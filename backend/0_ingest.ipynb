{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb4abe7-e97b-4b6e-b3b0-a75925bc1ab4",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ef1dc2-cbcc-4d3f-a805-2da31ed5af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset link: https://huggingface.co/datasets/hugfaceguy0001/stanford_plato\n",
    "dataset = load_dataset(\"hugfaceguy0001/stanford_plato\", cache_dir=\"../data/stanford/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a94be8-ef36-40ff-8240-06b76c93b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time we select 300 items\n",
    "# Ends with article \"decision theory\"\n",
    "dataset_subset = dataset['train'].select(range(300)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b0474-222e-45ab-86aa-f417ab915341",
   "metadata": {},
   "source": [
    "This dataset includes 1776 articles, each explaining one philosophy term/people/topic. It has 8 features:\n",
    "\n",
    "* shorturl: The shorturl for the article. For example, the shorturl 'abduction' correspond to the page https://plato.stanford.edu/entries/abduction/\n",
    "* title: The title of the article.\n",
    "* pubinfo: The publication information.\n",
    "* preamble: The preface text of the article. The data is a list, each item of the list is a paragraph of the data. I choose not to break the paragraph structure. Certainly, you can merge them by, for example, ''.join(data['preamble'])\n",
    "toc: Table of contents. Also represented as list. Each item is a dictionary, the 'content_title' is the main content title, and the 'sub_toc' is a list of subcontent titles.\n",
    "* main_text: The main text of the article. The data is also a list, each item represents a section of the article. Each item is a dictionary, 'section_title' is the title of the section, 'main_content' is a list of paragraphs before subsections, 'subsections' is a list of subsections, each item is also a dictionary, has its own title 'subsection_title' and list of paragraphs 'content'.\n",
    "* bibliography: list of bibliography.\n",
    "* related_entries: list of entries related to the current entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5968be09-1478-4f24-8e69-33834584f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_subset.to_pandas()\n",
    "df.to_csv(\"../data/stanford_plato_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17bd057-4eb8-487a-b3d8-cdef1c37a41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shorturl</th>\n",
       "      <th>title</th>\n",
       "      <th>pubinfo</th>\n",
       "      <th>preamble</th>\n",
       "      <th>toc</th>\n",
       "      <th>main_text</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>related_entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>First published Wed Mar 9, 2011; substantive r...</td>\n",
       "      <td>[\\nIn the philosophical literature, the term “...</td>\n",
       "      <td>[{'content_title': '1. Abduction: The General ...</td>\n",
       "      <td>[{'main_content': ['\n",
       "You happen to know that T...</td>\n",
       "      <td>[Achinstein, P., 2001. The Book of Evidence, O...</td>\n",
       "      <td>[{'href': '../epistemology-bayesian/', 'text':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abelard</td>\n",
       "      <td>Peter Abelard</td>\n",
       "      <td>First published Tue Aug 3, 2004; substantive r...</td>\n",
       "      <td>[\\nPeter Abelard (1079–21 April 1142) [‘Abaila...</td>\n",
       "      <td>[{'content_title': '1. Life and Works', 'sub_t...</td>\n",
       "      <td>[{'main_content': [], 'section_title': '1. Lif...</td>\n",
       "      <td>[Carmen ad Astralabium. Edited by J. M. A.\\nRu...</td>\n",
       "      <td>[{'href': '../aristotle-logic/', 'text': 'Aris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhidharma</td>\n",
       "      <td>Abhidharma</td>\n",
       "      <td>First published Mon Aug 16, 2010; substantive ...</td>\n",
       "      <td>[\\nThe first centuries after Śākyamuni Buddha’...</td>\n",
       "      <td>[{'content_title': '1. Abhidharma: its origins...</td>\n",
       "      <td>[{'main_content': ['\n",
       "The early history of Budd...</td>\n",
       "      <td>[[A] Aṅguttara-nikāya, [Dhs-a] Atthasālinī\\n(D...</td>\n",
       "      <td>[{'href': '../atomism-modern/', 'text': 'atomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abilities</td>\n",
       "      <td>Abilities</td>\n",
       "      <td>First published Tue Jan 26, 2010; substantive ...</td>\n",
       "      <td>[\\nIn the accounts we give of one another, cla...</td>\n",
       "      <td>[{'content_title': '1. A taxonomy', 'sub_toc':...</td>\n",
       "      <td>[{'main_content': ['\n",
       "What is an ability? On on...</td>\n",
       "      <td>[Albritton, Rogers, 1985. “Freedom of Will and...</td>\n",
       "      <td>[{'href': '../action/', 'text': 'action'}, {'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abner-burgos</td>\n",
       "      <td>Abner of Burgos</td>\n",
       "      <td>First published Mon Jul 9, 2012; substantive r...</td>\n",
       "      <td>[\\nAbner of Burgos (Alfonso de Valladolid; c. ...</td>\n",
       "      <td>[{'content_title': '1. Life', 'sub_toc': []}, ...</td>\n",
       "      <td>[{'main_content': ['\n",
       "There are not many source...</td>\n",
       "      <td>[Meyasher aqob, G. Gluskina (ed. and trans.), ...</td>\n",
       "      <td>[{'href': '../aristotle-natphil/', 'text': 'Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>abraham-daud</td>\n",
       "      <td>Abraham Ibn Daud</td>\n",
       "      <td>First published Sat Aug 26, 2006; substantive ...</td>\n",
       "      <td>[\\n\\nAbraham ibn Daud (c.1110–1180) can be reg...</td>\n",
       "      <td>[{'content_title': '1. Introduction', 'sub_toc...</td>\n",
       "      <td>[{'main_content': ['\n",
       "\n",
       "In the introduction to h...</td>\n",
       "      <td>[Cohen, G.D. (ed.), 1967, A critical edition w...</td>\n",
       "      <td>[{'href': '../arabic-islamic-judaic/', 'text':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>david</td>\n",
       "      <td>David</td>\n",
       "      <td>First published Mon Sep 8, 2003; substantive r...</td>\n",
       "      <td>[\\n\\n‘David’ is named in certain manuscripts o...</td>\n",
       "      <td>[{'content_title': '1. Introduction', 'sub_toc...</td>\n",
       "      <td>[{'main_content': ['\n",
       "\n",
       "Byzantium in the 6th cen...</td>\n",
       "      <td>[Aversatjan, S., 1981. “David l’Invincible et ...</td>\n",
       "      <td>[{'href': '../ammonius/', 'text': 'Ammonius'},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>davidson</td>\n",
       "      <td>Donald Davidson</td>\n",
       "      <td>First published Wed May 29, 1996; substantive ...</td>\n",
       "      <td>[\\nDonald Davidson was one of the most importa...</td>\n",
       "      <td>[{'content_title': '1. Biographical Sketch', '...</td>\n",
       "      <td>[{'main_content': ['\n",
       "Donald Herbert Davidson w...</td>\n",
       "      <td>[1957, Decision-Making: An Experimental Approa...</td>\n",
       "      <td>[{'href': '../action/', 'text': 'action'}, {'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>death</td>\n",
       "      <td>Death</td>\n",
       "      <td>First published Wed May 22, 2002; substantive ...</td>\n",
       "      <td>[\\nThis article considers several questions co...</td>\n",
       "      <td>[{'content_title': '1. Life', 'sub_toc': ['1.1...</td>\n",
       "      <td>[{'main_content': ['\n",
       "To die is to cease to be ...</td>\n",
       "      <td>[Altshuler, R., 2016. “Immortality, Identity, ...</td>\n",
       "      <td>[{'href': '../death-definition/', 'text': 'dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>decision-theory</td>\n",
       "      <td>Decision Theory</td>\n",
       "      <td>First published Wed Dec 16, 2015; substantive ...</td>\n",
       "      <td>[\\nDecision theory is concerned with the reaso...</td>\n",
       "      <td>[{'content_title': '1. What are ', 'sub_toc': ...</td>\n",
       "      <td>[{'main_content': ['\n",
       "The two central concepts ...</td>\n",
       "      <td>[Al-Najjar, Nabil I. and Jonathan Weinstein, 2...</td>\n",
       "      <td>[{'href': '../decision-causal/', 'text': 'deci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            shorturl             title  \\\n",
       "0          abduction         Abduction   \n",
       "1            abelard     Peter Abelard   \n",
       "2         abhidharma        Abhidharma   \n",
       "3          abilities         Abilities   \n",
       "4       abner-burgos   Abner of Burgos   \n",
       "..               ...               ...   \n",
       "295     abraham-daud  Abraham Ibn Daud   \n",
       "296            david             David   \n",
       "297         davidson   Donald Davidson   \n",
       "298            death             Death   \n",
       "299  decision-theory   Decision Theory   \n",
       "\n",
       "                                               pubinfo  \\\n",
       "0    First published Wed Mar 9, 2011; substantive r...   \n",
       "1    First published Tue Aug 3, 2004; substantive r...   \n",
       "2    First published Mon Aug 16, 2010; substantive ...   \n",
       "3    First published Tue Jan 26, 2010; substantive ...   \n",
       "4    First published Mon Jul 9, 2012; substantive r...   \n",
       "..                                                 ...   \n",
       "295  First published Sat Aug 26, 2006; substantive ...   \n",
       "296  First published Mon Sep 8, 2003; substantive r...   \n",
       "297  First published Wed May 29, 1996; substantive ...   \n",
       "298  First published Wed May 22, 2002; substantive ...   \n",
       "299  First published Wed Dec 16, 2015; substantive ...   \n",
       "\n",
       "                                              preamble  \\\n",
       "0    [\\nIn the philosophical literature, the term “...   \n",
       "1    [\\nPeter Abelard (1079–21 April 1142) [‘Abaila...   \n",
       "2    [\\nThe first centuries after Śākyamuni Buddha’...   \n",
       "3    [\\nIn the accounts we give of one another, cla...   \n",
       "4    [\\nAbner of Burgos (Alfonso de Valladolid; c. ...   \n",
       "..                                                 ...   \n",
       "295  [\\n\\nAbraham ibn Daud (c.1110–1180) can be reg...   \n",
       "296  [\\n\\n‘David’ is named in certain manuscripts o...   \n",
       "297  [\\nDonald Davidson was one of the most importa...   \n",
       "298  [\\nThis article considers several questions co...   \n",
       "299  [\\nDecision theory is concerned with the reaso...   \n",
       "\n",
       "                                                   toc  \\\n",
       "0    [{'content_title': '1. Abduction: The General ...   \n",
       "1    [{'content_title': '1. Life and Works', 'sub_t...   \n",
       "2    [{'content_title': '1. Abhidharma: its origins...   \n",
       "3    [{'content_title': '1. A taxonomy', 'sub_toc':...   \n",
       "4    [{'content_title': '1. Life', 'sub_toc': []}, ...   \n",
       "..                                                 ...   \n",
       "295  [{'content_title': '1. Introduction', 'sub_toc...   \n",
       "296  [{'content_title': '1. Introduction', 'sub_toc...   \n",
       "297  [{'content_title': '1. Biographical Sketch', '...   \n",
       "298  [{'content_title': '1. Life', 'sub_toc': ['1.1...   \n",
       "299  [{'content_title': '1. What are ', 'sub_toc': ...   \n",
       "\n",
       "                                             main_text  \\\n",
       "0    [{'main_content': ['\n",
       "You happen to know that T...   \n",
       "1    [{'main_content': [], 'section_title': '1. Lif...   \n",
       "2    [{'main_content': ['\n",
       "The early history of Budd...   \n",
       "3    [{'main_content': ['\n",
       "What is an ability? On on...   \n",
       "4    [{'main_content': ['\n",
       "There are not many source...   \n",
       "..                                                 ...   \n",
       "295  [{'main_content': ['\n",
       "\n",
       "In the introduction to h...   \n",
       "296  [{'main_content': ['\n",
       "\n",
       "Byzantium in the 6th cen...   \n",
       "297  [{'main_content': ['\n",
       "Donald Herbert Davidson w...   \n",
       "298  [{'main_content': ['\n",
       "To die is to cease to be ...   \n",
       "299  [{'main_content': ['\n",
       "The two central concepts ...   \n",
       "\n",
       "                                          bibliography  \\\n",
       "0    [Achinstein, P., 2001. The Book of Evidence, O...   \n",
       "1    [Carmen ad Astralabium. Edited by J. M. A.\\nRu...   \n",
       "2    [[A] Aṅguttara-nikāya, [Dhs-a] Atthasālinī\\n(D...   \n",
       "3    [Albritton, Rogers, 1985. “Freedom of Will and...   \n",
       "4    [Meyasher aqob, G. Gluskina (ed. and trans.), ...   \n",
       "..                                                 ...   \n",
       "295  [Cohen, G.D. (ed.), 1967, A critical edition w...   \n",
       "296  [Aversatjan, S., 1981. “David l’Invincible et ...   \n",
       "297  [1957, Decision-Making: An Experimental Approa...   \n",
       "298  [Altshuler, R., 2016. “Immortality, Identity, ...   \n",
       "299  [Al-Najjar, Nabil I. and Jonathan Weinstein, 2...   \n",
       "\n",
       "                                       related_entries  \n",
       "0    [{'href': '../epistemology-bayesian/', 'text':...  \n",
       "1    [{'href': '../aristotle-logic/', 'text': 'Aris...  \n",
       "2    [{'href': '../atomism-modern/', 'text': 'atomi...  \n",
       "3    [{'href': '../action/', 'text': 'action'}, {'h...  \n",
       "4    [{'href': '../aristotle-natphil/', 'text': 'Ar...  \n",
       "..                                                 ...  \n",
       "295  [{'href': '../arabic-islamic-judaic/', 'text':...  \n",
       "296  [{'href': '../ammonius/', 'text': 'Ammonius'},...  \n",
       "297  [{'href': '../action/', 'text': 'action'}, {'h...  \n",
       "298  [{'href': '../death-definition/', 'text': 'dea...  \n",
       "299  [{'href': '../decision-causal/', 'text': 'deci...  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f48c8dc-2bf9-4e4c-9ad5-0409feff84d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shorturl': 'abduction',\n",
       " 'title': 'Abduction',\n",
       " 'pubinfo': 'First published Wed Mar 9, 2011; substantive revision Tue May 18, 2021',\n",
       " 'preamble': ['\\nIn the philosophical literature, the term “abduction” is\\nused in two related but different senses. In both senses, the term\\nrefers to some form of explanatory reasoning. However, in the\\nhistorically first sense, it refers to the place of explanatory\\nreasoning in generating hypotheses, while in the sense in\\nwhich it is used most frequently in the modern literature it refers to\\nthe place of explanatory reasoning in justifying hypotheses.\\nIn the latter sense, abduction is also often called “Inference\\nto the Best Explanation.”',\n",
       "  '\\nThis entry is exclusively concerned with abduction in the modern\\nsense, although there is a supplement on abduction in the historical\\nsense, which had its origin in the work of Charles Sanders\\nPeirce—see the',\n",
       "  '\\nSee also the entry on\\n scientific discovery,\\n in particular the section on discovery as abduction.',\n",
       "  '\\nMost philosophers agree that abduction (in the sense of Inference to\\nthe Best Explanation) is a type of inference that is frequently\\nemployed, in some form or other, both in everyday and in scientific\\nreasoning. However, the exact form as well as the normative status of\\nabduction are still matters of controversy. This entry contrasts\\nabduction with other types of inference; points at prominent uses of\\nit, both in and outside philosophy; considers various more or less\\nprecise statements of it; discusses its normative status; and\\nhighlights possible connections between abduction and Bayesian\\nconfirmation theory.'],\n",
       " 'toc': [{'content_title': '1. Abduction: The General Idea',\n",
       "   'sub_toc': ['1.1 Deduction, induction, abduction',\n",
       "    '1.2 The ubiquity of abduction']},\n",
       "  {'content_title': '2. Explicating Abduction', 'sub_toc': []},\n",
       "  {'content_title': '3. The Status of Abduction',\n",
       "   'sub_toc': ['3.1 Criticisms', '3.2 Defenses']},\n",
       "  {'content_title': '4. Abduction versus Bayesian Confirmation Theory',\n",
       "   'sub_toc': []},\n",
       "  {'content_title': 'Bibliography', 'sub_toc': []},\n",
       "  {'content_title': 'Academic Tools', 'sub_toc': []},\n",
       "  {'content_title': 'Other Internet Resources', 'sub_toc': []},\n",
       "  {'content_title': 'Related Entries', 'sub_toc': []}],\n",
       " 'main_text': [{'main_content': ['\\nYou happen to know that Tim and Harry have recently had a terrible row\\nthat ended their friendship. Now someone tells you that she just saw\\nTim and Harry jogging together. The best explanation for this that you\\ncan think of is that they made up. You conclude that they are friends\\nagain.',\n",
       "    '\\nOne morning you enter the kitchen to find a plate and cup on the\\ntable, with breadcrumbs and a pat of butter on it, and surrounded by a\\njar of jam, a pack of sugar, and an empty carton of milk. You conclude\\nthat one of your house-mates got up at night to make him- or herself a\\nmidnight snack and was too tired to clear the table. This, you think,\\nbest explains the scene you are facing. To be sure, it might be that\\nsomeone burgled the house and took the time to have a bite while on\\nthe job, or a house-mate might have arranged the things on the table\\nwithout having a midnight snack but just to make you believe that\\nsomeone had a midnight snack. But these hypotheses strike you as\\nproviding much more contrived explanations of the data than the one\\nyou infer to.',\n",
       "    '\\nWalking along the beach, you see what looks like a picture of Winston\\nChurchill in the sand. It could be that, as in the opening pages of\\nHilary Putnam’s book Reason, Truth, and History,\\n(1981), what you see is actually the trace of an ant crawling on the\\nbeach. The much simpler, and therefore (you think) much better,\\nexplanation is that someone intentionally drew a picture of Churchill\\nin the sand. That, in any case, is what you come away believing.',\n",
       "    '\\nIn these examples, the conclusions do not follow logically from the\\npremises. For instance, it does not follow logically that Tim and\\nHarry are friends again from the premises that they had a terrible row\\nwhich ended their friendship and that they have just been seen jogging\\ntogether; it does not even follow, we may suppose, from all the\\ninformation you have about Tim and Harry. Nor do you have any useful\\nstatistical data about friendships, terrible rows, and joggers that\\nmight warrant an inference from the information that you have about\\nTim and Harry to the conclusion that they are friends again, or even\\nto the conclusion that, probably (or with a certain probability), they\\nare friends again. What leads you to the conclusion, and what\\naccording to a considerable number of philosophers may also warrant\\nthis conclusion, is precisely the fact that Tim and Harry’s\\nbeing friends again would, if true, best explain the\\nfact that they have just been seen jogging together. (The proviso that\\na hypothesis be true if it is to explain anything is taken as read\\nfrom here on.) Similar remarks apply to the other two examples. The\\ntype of inference exhibited here is called abduction or,\\nsomewhat more commonly nowadays, Inference to the Best\\nExplanation.'],\n",
       "   'section_title': '1. Abduction: The General Idea',\n",
       "   'subsections': [{'content': ['\\nAbduction is normally thought of as being one of three major types of\\ninference, the other two being deduction and induction. The\\ndistinction between deduction, on the one hand, and induction and\\nabduction, on the other hand, corresponds to the distinction between\\nnecessary and non-necessary inferences. In deductive inferences, what\\nis inferred is necessarily true if the premises from which it\\nis inferred are true; that is, the truth of the premises\\nguarantees the truth of the conclusion. A familiar type of\\nexample is inferences instantiating the schema',\n",
       "      '\\nAll As are Bs.\\n\\na is an A.\\n\\nHence, a is a B.\\n',\n",
       "      '\\nBut not all inferences are of this variety. Consider, for instance,\\nthe inference of “John is rich” from “John lives in\\nChelsea” and “Most people living in Chelsea are\\nrich.” Here, the truth of the first sentence is not guaranteed\\n(but only made likely) by the joint truth of the second and third\\nsentences. Differently put, it is not necessarily the case that if the\\npremises are true, then so is the conclusion: it is logically\\ncompatible with the truth of the premises that John is a member of the\\nminority of non-rich inhabitants of Chelsea. The case is similar\\nregarding your inference to the conclusion that Tim and Harry are\\nfriends again on the basis of the information that they have been seen\\njogging together. Perhaps Tim and Harry are former business partners\\nwho still had some financial matters to discuss, however much they\\nwould have liked to avoid this, and decided to combine this with their\\ndaily exercise; this is compatible with their being firmly decided\\nnever to make up.',\n",
       "      '\\nIt is standard practice to group non-necessary inferences into\\ninductive and abductive ones. Inductive inferences\\nform a somewhat heterogeneous class, but for present purposes they may\\nbe characterized as those inferences that are based purely on\\nstatistical data, such as observed frequencies of occurrences of a\\nparticular feature in a given population. An example of such an\\ninference would be this:',\n",
       "      '\\n96 per cent of the Flemish college students speak both Dutch and\\nFrench.\\n\\nLouise is a Flemish college student.\\n\\nHence, Louise speaks both Dutch and French.\\n',\n",
       "      '\\nHowever, the relevant statistical information may also be more vaguely\\ngiven, as in the premise, “Most people living in Chelsea are\\nrich.” (There is much discussion about whether the conclusion of\\nan inductive argument can be stated in purely qualitative terms or\\nwhether it should be a quantitative one—for instance, that it\\nholds with a probability of .96 that Louise speaks both Dutch and\\nFrench—or whether it can sometimes be stated in\\nqualitative terms—for instance, if the probability that it is\\ntrue is high enough—and sometimes not. On these and other issues\\nrelated to induction, see Kyburg 1990 (Ch. 4). It should also be\\nmentioned that Harman (1965) conceives induction as a special type of\\nabduction. See also Weintraub 2013 for discussion.)',\n",
       "      '\\nThe mere fact that an inference is based on statistical data is not\\nenough to classify it as an inductive one. You may have observed many\\ngray elephants and no non-gray ones, and infer from this that all\\nelephants are gray, because that would provide the best\\nexplanation for why you have observed so many gray elephants\\nand no non-gray ones. This would be an instance of an\\nabductive inference. It suggests that the best way to distinguish\\nbetween induction and abduction is this: both are ampliative,\\nmeaning that the conclusion goes beyond what is (logically) contained\\nin the premises (which is why they are non-necessary inferences), but\\nin abduction there is an implicit or explicit appeal to explanatory\\nconsiderations, whereas in induction there is not; in induction, there\\nis only an appeal to observed frequencies or statistics. (I\\nemphasize “only,” because in abduction there may also be\\nan appeal to frequencies or statistics, as the example about the\\nelephants exhibits.)',\n",
       "      '\\nA noteworthy feature of abduction, which it shares with induction but\\nnot with deduction, is that it violates monotonicity, meaning\\nthat it may be possible to infer abductively certain conclusions from\\na subset of a set S of premises which cannot be\\ninferred abductively from S as a whole. For instance, adding\\nthe premise that Tim and Harry are former business partners who still\\nhave some financial matters to discuss, to the premises that they had\\na terrible row some time ago and that they were just seen jogging\\ntogether may no longer warrant you to infer that they are friends\\nagain, even if—let us suppose—the last two premises alone\\ndo warrant that inference. The reason is that what counts as the best\\nexplanation of Tim and Harry’s jogging together in light of the\\noriginal premises may no longer do so once the information has been\\nadded that they are former business partners with financial matters to\\ndiscuss.'],\n",
       "     'subsection_title': '1.1 Deduction, induction, abduction'},\n",
       "    {'content': ['\\nThe type of inference exemplified in the cases described at the\\nbeginning of this entry will strike most as entirely familiar.\\nPhilosophers as well as psychologists tend to agree that abduction is\\nfrequently employed in everyday reasoning. Sometimes our reliance on\\nabductive reasoning is quite obvious and explicit. But in some daily\\npractices, it may be so routine and automatic that it easily goes\\nunnoticed. A case in point may be our trust in other people’s\\ntestimony, which has been said to rest on abductive reasoning; see\\nHarman 1965, Adler 1994, Fricker 1994, and Lipton 1998 for defenses of\\nthis claim. For instance, according to Jonathan Adler (1994, 274f),\\n“[t]he best explanation for why the informant asserts that\\nP is normally that … he believes it for duly responsible\\nreasons and … he intends that I shall believe it too,”\\nwhich is why we are normally justified in trusting the\\ninformant’s testimony. This may well be correct, even though in\\ncoming to trust a person’s testimony one does not normally seem\\nto be aware of any abductive reasoning going on in one’s mind.\\nSimilar remarks may apply to what some hold to be a further, possibly\\neven more fundamental, role of abduction in linguistic practice, to\\nwit, its role in determining what a speaker means by an utterance.\\nSpecifically, it has been argued that decoding utterances is a matter\\nof inferring the best explanation of why someone said what he or she\\nsaid in the context in which the utterance was made. Even more\\nspecifically, authors working in the field of pragmatics have\\nsuggested that hearers invoke the Gricean maxims of conversation to\\nhelp them work out the best explanation of a speaker’s utterance\\nwhenever the semantic content of the utterance is insufficiently\\ninformative for the purposes of the conversation, or is too\\ninformative, or off-topic, or implausible, or otherwise odd or\\ninappropriate; see, for instance, Bach and Harnish 1979 (92f), Dascal\\n1979 (167), and Hobbs 2004. As in cases of reliance on speaker\\ntestimony, the requisite abductive reasoning would normally seem to\\ntake place at a subconscious level.',\n",
       "      '\\nAbductive reasoning is not limited to everyday contexts. Quite the\\ncontrary: philosophers of science have argued that abduction is a\\ncornerstone of scientific methodology; see, for instance, Boyd 1981,\\n1984, Harré 1986, 1988, Lipton 1991, 2004, and Psillos 1999.\\nAccording to Timothy Williamson (2007), “[t]he abductive\\nmethodology is the best science provides” and Ernan McMullin\\n(1992) even goes so far to call abduction “the inference that\\nmakes science.” To illustrate the use of abduction in science,\\nwe consider two examples.',\n",
       "      '\\nAt the beginning of the nineteenth century, it was discovered that the\\norbit of Uranus, one of the seven planets known at the time, departed\\nfrom the orbit as predicted on the basis of Isaac Newton’s\\ntheory of universal gravitation and the auxiliary assumption that\\nthere were no further planets in the solar system. One possible\\nexplanation was, of course, that Newton’s theory is false. Given\\nits great empirical successes for (then) more than two centuries, that\\ndid not appear to be a very good explanation. Two astronomers, John\\nCouch Adams and Urbain Leverrier, instead suggested (independently of\\neach other but almost simultaneously) that there was an eighth, as yet\\nundiscovered planet in the solar system; that, they thought, provided\\nthe best explanation of Uranus’ deviating orbit. Not much later,\\nthis planet, which is now known as “Neptune,” was\\ndiscovered.',\n",
       "      '\\nThe second example concerns what is now commonly regarded to have been\\nthe discovery of the electron by the English physicist Joseph John\\nThomson. Thomson had conducted experiments on cathode rays in order to\\ndetermine whether they are streams of charged particles. He concluded\\nthat they are indeed, reasoning as follows:',\n",
       "      '\\n\\n\\nAs the cathode rays carry a charge of negative electricity, are\\ndeflected by an electrostatic force as if they were negatively\\nelectrified, and are acted on by a magnetic force in just the way in\\nwhich this force would act on a negatively electrified body moving\\nalong the path of these rays, I can see no escape from the conclusion\\nthat they are charges of negative electricity carried by particles of\\nmatter. (Thomson, cited in Achinstein 2001, 17)\\n',\n",
       "      '\\nThe conclusion that cathode rays consist of negatively charged\\nparticles does not follow logically from the reported experimental\\nresults, nor could Thomson draw on any relevant statistical data. That\\nnevertheless he could “see no escape from the conclusion”\\nis, we may safely assume, because the conclusion is the best—in\\nthis case presumably even the only plausible—explanation of his\\nresults that he could think of.',\n",
       "      '\\nMany other examples of scientific uses of abduction have been\\ndiscussed in the literature; see, for instance, Harré 1986,\\n1988 and Lipton 1991, 2004. Abduction is also said to be the\\npredominant mode of reasoning in medical diagnosis: physicians tend to\\ngo for the hypothesis that best explains the patient’s symptoms\\n(see Josephson and Josephson (eds.) 1994, 9–12; see also\\nDragulinescu 2016 on abductive reasoning in the context of\\nmedicine).',\n",
       "      '\\nLast but not least, abduction plays a central role in some important\\nphilosophical debates. See Shalkowski 2010 on the place of abduction\\nin metaphysics (also Bigelow 2010), Krzyżanowska, Wenmackers, and\\nDouven 2014 and Douven 2016a for a possible role of\\nabduction in the semantics of conditionals, and Williamson\\n2017 for an application of abduction in the philosophy of logic.\\nArguably, however, abduction plays its most notable philosophical role\\nin epistemology and in the philosophy of science, where it is\\nfrequently invoked in objections to so-called underdetermination\\narguments. Underdetermination arguments generally start from the\\npremise that a number of given hypotheses are empirically equivalent,\\nwhich their authors take to mean that the evidence—indeed, any\\nevidence we might ever come to possess—is unable to favor one of\\nthem over the others. From this, we are supposed to conclude that one\\ncan never be warranted in believing any particular one of the\\nhypotheses. (This is rough, but it will do for present purposes; see\\nDouven 2008 and Stanford 2009, for more detailed accounts of\\nunderdetermination arguments.) A famous instance of this type of\\nargument is the Cartesian argument for global skepticism, according to\\nwhich the hypothesis that reality is more or less the way we\\ncustomarily deem it to be is empirically equivalent to a variety of\\nso-called skeptical hypotheses (such as that we are beguiled by an\\nevil demon, or that we are brains in a vat, connected to a\\nsupercomputer; see, e.g., Folina 2016). Similar arguments have been\\ngiven in support of scientific antirealism, according to which it will\\nnever be warranted for us to choose between empirically equivalent\\nrivals concerning what underlies the observable part of reality (van\\nFraassen 1980).',\n",
       "      '\\nResponses to these arguments typically point to the fact that the\\nnotion of empirical equivalence at play unduly neglects explanatory\\nconsiderations, for instance, by defining the notion strictly in terms\\nof hypotheses’ making the same predictions. Those responding\\nthen argue that even if some hypotheses make exactly the same\\npredictions, one of them may still be a better explanation of the\\nphenomena predicted. Thus, if explanatory considerations have a role\\nin determining which inferences we are licensed to make—as\\naccording to defenders of abduction they have—then we might\\nstill be warranted in believing in the truth (or probable truth, or\\nsome such, depending—as will be seen below—on the version\\nof abduction one assumes) of one of a number of hypotheses that all\\nmake the same predictions. Following Bertrand Russell (1912, Ch. 2),\\nmany epistemologists have invoked abduction in arguing against\\nCartesian skepticism, their key claim being that even though, by\\nconstruction, the skeptical hypotheses make the same predictions as\\nthe hypothesis that reality is more or less the way we ordinarily take\\nit to be, they are not equally good explanations of what they predict;\\nin particular, the skeptical hypotheses have been said to be\\nconsiderably less simple than the “ordinary world”\\nhypothesis. See, among many others, Harman 1973 (Chs. 8 and 11),\\nGoldman 1988 (205), Moser 1989 (161), and Vogel 1990, 2005; see\\nPargetter 1984 for an abductive response specifically to skepticism\\nregarding other minds. Similarly, philosophers of science have argued\\nthat we are warranted to believe in Special Relativity Theory as\\nopposed to Lorentz’s version of the æther theory. For even\\nthough these theories make the same predictions, the former is\\nexplanatorily superior to the latter. (Most arguments that have been\\ngiven for this claim come down to the contention that Special\\nRelativity Theory is ontologically more parsimonious than its\\ncompetitor, which postulates the existence of an æther. See\\nJanssen 2002 for an excellent discussion of the various reasons\\nphilosophers of science have adduced for preferring Einstein’s\\ntheory to Lorentz’s.)'],\n",
       "     'subsection_title': '1.2 The ubiquity of abduction'}]},\n",
       "  {'main_content': ['\\nPrecise statements of what abduction amounts to are rare in the\\nliterature on abduction. (Peirce did propose an at least fairly\\nprecise statement; but, as explained in the supplement to this entry,\\nit does not capture what most nowadays understand by abduction.) Its\\ncore idea is often said to be that explanatory considerations have\\nconfirmation-theoretic import, or that explanatory success is a (not\\nnecessarily unfailing) mark of truth. Clearly, however, these\\nformulations are slogans at best, and it takes little effort to see\\nthat they can be cashed out in a great variety of prima facie\\nplausible ways. Here we will consider a number of such possible\\nexplications, starting with what one might term the “textbook\\nversion of abduction,” which, as will be seen, is manifestly\\ndefective, and then going on to consider various possible refinements\\nof it. What those versions have in\\ncommon—unsurprisingly—is that they are all inference\\nrules, requiring premises encompassing explanatory considerations and\\nyielding a conclusion that makes some statement about the truth of a\\nhypothesis. The differences concern the premises that are required, or\\nwhat exactly we are allowed to infer from them (or both).',\n",
       "    '\\nIn textbooks on epistemology or the philosophy of science, one often\\nencounters something like the following as a formulation of\\nabduction:',\n",
       "    '\\nAn observation that is frequently made about this rule, and that\\npoints to a potential problem for it, is that it presupposes the\\nnotions of candidate explanation and best explanation, neither of\\nwhich has a straightforward interpretation. While some still hope that\\nthe former can be spelled out in purely logical, or at least purely\\nformal, terms, it is often said that the latter must appeal to the\\nso-called theoretical virtues, like simplicity, generality, and\\ncoherence with well-established theories; the best explanation would\\nthen be the hypothesis which, on balance, does best with respect to\\nthese virtues. (See, for instance, Thagard 1978 and McMullin 1996.)\\nThe problem is that none of the said virtues is presently particularly\\nwell understood. (Giere, in Callebaut (ed.) 1993 (232), even makes the\\nradical claim that the theoretical virtues lack real content and play\\nno more than a rhetorical role in science. In view of recent formal\\nwork both on simplicity and on coherence—for instance, Forster\\nand Sober 1994, Li and Vitanyi 1997, and Sober 2015, on simplicity and\\nBovens and Hartmann 2003 and Olsson 2005, on coherence—the first\\npart of this claim has become hard to maintain; also, Schupbach and\\nSprenger (2011) present an account of explanatory goodness directly in\\nprobabilistic terms. Psychological evidence casts doubt on the second\\npart of the claim; see, for instance, Lombrozo 2007, on the role of\\nsimplicity in people’s assessments of explanatory goodness and\\nKoslowski et al. 2008, on the role of coherence with\\nbackground knowledge in those assessments.)',\n",
       "    '\\nFurthermore, many of those who think ABD1 is headed along the right\\nlines believe that it is too strong. Some think that abduction\\nwarrants an inference only to the probable truth of the best\\nexplanation, others that it warrants an inference only to the\\napproximate truth of the best explanation, and still others\\nthat it warrants an inference only to the probable\\napproximate truth.',\n",
       "    '\\nThe real problem with ABD1 runs deeper than this, however. Because\\nabduction is ampliative—as explained earlier—it will not\\nbe a sound rule of inference in the strict logical sense, however\\nabduction is explicated exactly. It can still be reliable in\\nthat it mostly leads to a true conclusion whenever the premises are\\ntrue. An obvious necessary condition for ABD1 to be reliable in this\\nsense is that, mostly, when it is true that H best\\nexplains E, and E is true, then H is true as well\\n(or H is approximately true, or probably true, or probably\\napproximately true). But this would not be enough for ABD1 to\\nbe reliable. For ABD1 takes as its premise only that some hypothesis\\nis the best explanation of the evidence as compared to other\\nhypotheses in a given set. Thus, if the rule is to be\\nreliable, it must hold that, at least typically, the best explanation\\nrelative to the set of hypotheses that we consider would also come out\\nas being best in comparison with any other hypotheses that we might\\nhave conceived (but for lack of time or ingenuity, or for some other\\nreason, did not conceive). In other words, it must hold that at least\\ntypically the absolutely best explanation of the evidence is\\nto be found among the candidate explanations we have come up with, for\\nelse ABD1 may well lead us to believe “the best of a bad\\nlot” (van Fraassen 1989, 143).',\n",
       "    '\\nHow reasonable is it to suppose that this extra requirement is usually\\nfulfilled? Not at all, presumably. To believe otherwise, we must\\nassume some sort of privilege on our part to the effect that when we\\nconsider possible explanations of the data, we are somehow predisposed\\nto hit, inter alia, upon the absolutely best explanation of those\\ndata. After all, hardly ever will we have considered, or will it even\\nbe possible to consider, all potential explanations. As van\\nFraassen (1989, 144) points out, it is a priori rather\\nimplausible to hold that we are thus privileged.',\n",
       "    '\\nIn response to this, one might argue that the challenge to show that\\nthe best explanation is always or mostly among the hypotheses\\nconsidered can be met without having to assume some form of privilege\\n(see Schupbach 2014 for a different response, and see Dellsén\\n2017 for discussion). For given the hypotheses we have managed to come\\nup with, we can always generate a set of hypotheses which jointly\\nexhaust logical space. Suppose\\nH1,…,Hn are the\\ncandidate explanations we have so far been able to conceive. Then\\nsimply define Hn+1 := ¬H1\\n∧ … ∧ ¬Hn and add this new\\nhypothesis as a further candidate explanation to the ones we already\\nhave. Obviously, the set\\n{H1,…,Hn+1} is exhaustive,\\nin that one of its elements must be true. Following this in itself\\nsimple procedure would seem enough to make sure that we never miss out\\non the absolutely best explanation. (See Lipton 1993, for a proposal\\nalong these lines.)',\n",
       "    '\\nAlas, there is a catch. For even though there may be many hypotheses\\nHj that imply Hn+1 and, had\\nthey been formulated, would have been evaluated as being a better\\nexplanation for the data than the best explanation among the candidate\\nexplanations we started out with, Hn+1 itself will\\nin general be hardly informative; in fact, in general it will not even\\nbe clear what its empirical consequences are. Suppose, for instance,\\nwe have as competing explanations Special Relativity Theory and\\nLorentz’s version of the æther theory. Then, following the\\nabove proposal, we may add to our candidate explanations that neither\\nof these two theories is true. But surely this further hypothesis will\\nbe ranked quite low qua explanation—if it will be\\nranked at all, which seems doubtful, given that it is wholly unclear\\nwhat its empirical consequences are. This is not to say that the\\nsuggested procedure may never work. The point is that in general it\\nwill give little assurance that the best explanation is among the\\ncandidate explanations we consider.',\n",
       "    '\\nA more promising response to the above “argument of the bad\\nlot” begins with the observation that the argument capitalizes\\non a peculiar asymmetry or incongruence in ABD1. The rule gives\\nlicense to an absolute conclusion—that a given hypothesis is\\ntrue—on the basis of a comparative premise, namely, that that\\nparticular hypothesis is the best explanation of the evidence relative\\nto the other hypotheses available (see Kuipers 2000, 171). This\\nincongruence is not avoided by replacing “truth” with\\n“probable truth” or “approximate truth.” In\\norder to avoid it, one has two general options.',\n",
       "    '\\nThe first option is to modify the rule so as to have it require an\\nabsolute premise. For instance, following Alan Musgrave (1988) or\\nPeter Lipton (1993), one may require the hypothesis whose truth is\\ninferred to be not only the best of the available potential\\nexplanations, but also to be satisfactory (Musgrave) or\\ngood enough (Lipton), yielding the following variant of\\nABD1:',\n",
       "    '\\nNeedless to say, ABD2 needs supplementing by a criterion for the\\nsatisfactoriness of explanations, or their being good enough, which,\\nhowever, we are still lacking.',\n",
       "    '\\nSecondly, one can formulate a symmetric or congruous version of\\nabduction by having it sanction, given a comparative premise, only a\\ncomparative conclusion; this option, too, can in turn be realized in\\nmore than one way. Here is one way to do it, which has been proposed\\nand defended in the work of Theo Kuipers (e.g., Kuipers 1984, 1992,\\n2000).',\n",
       "    '\\nClearly, ABD3 requires an account of closeness to the truth, but many\\nsuch accounts are on offer today (see, e.g., Niiniluoto 1998).',\n",
       "    '\\nOne noteworthy feature of the congruous versions of abduction\\nconsidered here is that they do not rely on the assumption of an\\nimplausible privilege on the reasoner’s part that, we saw, ABD1\\nimplicitly relies on. Another is that if one can be certain that,\\nhowever many candidate explanations for the data one may have missed,\\nnone equals the best of those one has thought of, then the\\ncongruous versions license exactly the same inference as ABD1 does\\n(supposing that one would not be certain that no potential explanation\\nis as good as the best explanation one has thought of if the latter is\\nnot even satisfactory or sufficiently good).',\n",
       "    '\\nAs mentioned, there is widespread agreement that people frequently\\nrely on abductive reasoning. Which of the above rules exactly\\nis it that people rely on? Or might it be still some further rule that\\nthey rely on? Or might they in some contexts rely on one version, and\\nin others on another (Douven 2017, forthcoming)? Philosophical\\nargumentation is unable to answer these questions. In recent years,\\nexperimental psychologists have started paying attention to the role\\nhumans give to explanatory considerations in reasoning. For instance,\\nTania Lombrozo and Nicholas Gwynne (2014) report experiments showing\\nthat how a property of a given class of things is explained\\nto us—whether mechanistically, by reference to parts and\\nprocesses, or functionally, by reference to functions and\\npurposes—matters to how likely we are to generalise that\\nproperty to other classes of things (see also Sloman 1994 and Williams\\nand Lombrozo 2010). And Igor Douven and Jonah Schupbach (2015a),\\n(2015b) present experimental evidence to the effect that\\npeople’s probability updates tend to be influenced by\\nexplanatory considerations in ways that makes them deviate from\\nstrictly Bayesian updates (see below). Douven (2016b) shows that, in\\nthe aforementioned experiments, participants who gave more weight to\\nexplanatory considerations tended to be more accurate, as determined\\nin terms of a standard scoring rule. (See Lombrozo 2012 and 2016 for\\nuseful overviews of recent experimental work relevant to explanation\\nand inference.) Douven and Patricia Mirabile (2018) found some\\nevidence indicating that people rely on something like ABD2, at least\\nin some contexts, but for the most part, empirical work on the\\nabove-mentioned questions is lacking.',\n",
       "    '\\nWith respect to the normative question of which of the previously\\nstated rules we ought to rely on (if we ought to rely on any\\nform of abduction), where philosophical argumentation should be able\\nto help, the situation is hardly any better. In view of the argument\\nof the bad lot, ABD1 does not look very good. Other arguments against\\nabduction are claimed to be independent of the exact explication of\\nthe rule; below, these arguments will be found wanting. On the other\\nhand, arguments that have been given in favor of abduction—some\\nof which will also be discussed below—do not discern between\\nspecific versions. So, supposing people do indeed commonly rely on\\nabduction, it must be considered an open question as to which\\nversion(s) of abduction they rely on. Equally, supposing it is\\nrational for people to rely on abduction, it must be considered an\\nopen question as to which version, or perhaps versions, of abduction\\nthey ought to, or are at least permitted to, rely on.'],\n",
       "   'section_title': '2. Explicating Abduction',\n",
       "   'subsections': []},\n",
       "  {'main_content': ['\\nEven if it is true that we routinely rely on abductive reasoning, it\\nmay still be asked whether this practice is rational. For instance,\\nexperimental studies have shown that when people are able to think of\\nan explanation for some possible event, they tend to overestimate the\\nlikelihood that this event will actually occur. (See Koehler 1991, for\\na survey of some of these studies; see also Brem and Rips 2000.) More\\ntelling still, Lombrozo (2007) shows that, in some situations, people\\ntend to grossly overrate the probability of simpler explanations\\ncompared to more complicated ones. Although these studies are not\\ndirectly concerned with abduction in any of the forms discussed so\\nfar, they nevertheless suggest that taking into account explanatory\\nconsiderations in one’s reasoning may not always be for the\\nbetter. (It is to be noted that Lombrozo’s experiments\\nare directly concerned with some proposals that have been\\nmade for explicating abduction in a Bayesian framework; see Section\\n4.) However, the most pertinent remarks about the normative status of\\nabduction are so far to be found in the philosophical literature. This\\nsection discusses the main criticisms that have been levelled against\\nabduction, as well as the strongest arguments that have been given in\\nits defense.'],\n",
       "   'section_title': '3. The Status of Abduction',\n",
       "   'subsections': [{'content': ['\\nWe have already encountered the so-called argument of the bad lot,\\nwhich, we saw, is valid as a criticism of ABD1 but powerless against\\nvarious (what we called) congruous rules of abduction. We here\\nconsider two objections that are meant to be more general. The first\\neven purports to challenge the core idea underlying abduction; the\\nsecond is not quite as general, but it is still meant to undermine a\\nbroad class of candidate explications of abduction. Both objections\\nare due to Bas van Fraassen.',\n",
       "      '\\nThe first objection has as a premise that it is part of the meaning of\\n“explanation” that if one theory is more explanatory than\\nanother, the former must be more informative than the latter (see,\\ne.g., van Fraassen 1983, Sect. 2). The alleged problem then is that it\\nis “an elementary logical point that a more informative theory\\ncannot be more likely to be true [and thus] attempts to describe\\ninductive or evidential support through features that require\\ninformation (such as ‘Inference to the Best Explanation’)\\nmust either contradict themselves or equivocate” (van Fraassen\\n1989, 192). The elementary logical point is supposed to be “most\\n[obvious] … in the paradigm case in which one theory is an\\nextension of another: clearly the extension has more ways of being\\nfalse” (van Fraassen 1985, 280).',\n",
       "      '\\nIt is important to note, however, that in any other kind of case than\\nthe “paradigm” one, the putative elementary point is not\\nobvious at all. For instance, it is entirely unclear in what sense\\nSpecial Relativity Theory “has more ways of being false”\\nthan Lorentz’s version of the æther theory, given that\\nthey make the same predictions. And yet the former is generally\\nregarded as being superior, qua explanation, to the latter.\\n(If van Fraassen were to object that the former is not really more\\ninformative than the latter, or at any rate not more informative in\\nthe appropriate sense—whatever that is—then we should\\ncertainly refuse to grant the premise that in order to be more\\nexplanatory a theory must be more informative.)',\n",
       "      '\\nThe second objection, proffered in van Fraassen 1989 (Ch. 6), is\\nlevelled at probabilistic versions of abduction. The objection is that\\nsuch rules must either amount to Bayes’ rule, and thus be\\nredundant, or be at variance with it but then, on the grounds of\\nLewis’ dynamic Dutch book argument (as reported in Teller 1973),\\nbe probabilistically incoherent, meaning that they may lead one to\\nassess as fair a number of bets which together ensure a financial\\nloss, come what may; and, van Fraassen argues, it would be irrational\\nto follow a rule that has this feature.',\n",
       "      '\\nHowever, this objection fares no better than the first. For one thing,\\nas Patrick Maher (1992) and Brian Skyrms (1993) have pointed out, a\\nloss in one respect may be outweighed by a benefit in another. It\\nmight be, for instance, that some probabilistic version of abduction\\ndoes much better, at least in our world, than Bayes’ rule, in\\nthat, on average, it approaches the truth faster in the sense that it\\nis faster in assigning a high probability (understood as probability\\nabove a certain threshold value) to the true hypothesis (see Douven\\n2013, 2020, and Douven and Wenmackers 2017; see Climenhaga\\n2017 for discussion). If it does, then following that rule\\ninstead of Bayes’ rule may have advantages which perhaps are not\\nso readily expressed in terms of money yet which should arguably be\\ntaken into account when deciding which rule to go by. It is, in short,\\nnot so clear whether following a probabilistically incoherent rule\\nmust be irrational.',\n",
       "      '\\nFor another thing, Douven (1999) argues that the question of whether a\\nprobabilistic rule is coherent is not one that can be settled\\nindependently of considering which other epistemic and\\ndecision-theoretic rules are deployed along with it; coherence should\\nbe understood as a property of packages of both epistemic and\\ndecision-theoretic rules, not of epistemic rules (such as\\nprobabilistic rules for belief change) in isolation. In the same\\npaper, a coherent package of rules is described which includes a\\nprobabilistic version of abduction. (See Kvanvig 1994, Harman 1997,\\nLeplin 1997, Niiniluoto 1999, and Okasha 2000, for different responses\\nto van Fraassen’s critique of probabilistic versions of\\nabduction.)'],\n",
       "     'subsection_title': '3.1 Criticisms'},\n",
       "    {'content': ['\\nHardly anyone nowadays would want to subscribe to a conception of\\ntruth that posits a necessary connection between explanatory force and\\ntruth—for instance, because it stipulates explanatory\\nsuperiority to be necessary for truth. As a result, a priori defenses\\nof abduction seem out of the question. Indeed, all defenses that have\\nbeen given so far are of an empirical nature in that they appeal to\\ndata that supposedly support the claim that (in some form) abduction\\nis a reliable rule of inference.',\n",
       "      '\\nThe best-known argument of this sort was developed by Richard Boyd in\\nthe 1980s (see Boyd 1981, 1984, 1985). It starts by underlining the\\ntheory-dependency of scientific methodology, which comprises methods\\nfor designing experiments, for assessing data, for choosing between\\nrival hypotheses, and so on. For instance, in considering possible\\nconfounding factors from which an experimental setup has to be\\nshielded, scientists draw heavily on already accepted theories. The\\nargument next calls attention to the apparent reliability of this\\nmethodology, which, after all, has yielded, and continues to yield,\\nimpressively accurate theories. In particular, by relying on this\\nmethodology, scientists have for some time now been able to find ever\\nmore instrumentally adequate theories. Boyd then argues that the\\nreliability of scientific methodology is best explained by assuming\\nthat the theories on which it relies are at least approximately true.\\nFrom this and from the fact that these theories were mostly arrived at\\nby abductive reasoning, he concludes that abduction must be a reliable\\nrule of inference.',\n",
       "      '\\nCritics have accused this argument of being circular. Specifically, it\\nhas been said that the argument rests on a premise—that\\nscientific methodology is informed by approximately true background\\ntheories—which in turn rests on an inference to the best\\nexplanation for its plausibility. And the reliability of this type of\\ninference is precisely what is at stake. (See, for instance, Laudan\\n1981 and Fine 1984.)',\n",
       "      '\\nTo this, Stathis Psillos (1999, Ch. 4) has responded by invoking a\\ndistinction credited to Richard Braithwaite, to wit, the distinction\\nbetween premise-circularity and rule-circularity. An argument is\\npremise-circular if its conclusion is amongst its premises. A\\nrule-circular argument, by contrast, is an argument of which the\\nconclusion asserts something about an inferential rule that is used in\\nthe very same argument. As Psillos urges, Boyd’s argument is\\nrule-circular, but not premise-circular, and rule-circular arguments,\\nPsillos contends, need not be viciously circular (even though\\na premise-circular argument is always viciously circular). To be more\\nprecise, in his view, an argument for the reliability of a given rule\\nR that essentially relies on R as an inferential\\nprinciple is not vicious, provided that the use of R does not\\nguarantee a positive conclusion about R’s reliability.\\nPsillos claims that in Boyd’s argument, this proviso is met. For\\nwhile Boyd concludes that the background theories on which scientific\\nmethodology relies are approximately true on the basis of an abductive\\nstep, the use of abduction itself does not guarantee the truth of his\\nconclusion. After all, granting the use of abduction does nothing to\\nensure that the best explanation of the success of scientific\\nmethodology is the approximate truth of the relevant background\\ntheories. Thus, Psillos concludes, Boyd’s argument still\\nstands.',\n",
       "      '\\nEven if the use of abduction in Boyd’s argument might have led\\nto the conclusion that abduction is not reliable, one may\\nstill have worries about the argument’s being rule-circular. For\\nsuppose that some scientific community relied not on abduction but on\\na rule that we may dub “Inference to the Worst\\nExplanation” (IWE), a rule that sanctions inferring to the\\nworst explanation of the available data. We may safely assume\\nthat the use of this rule mostly would lead to the adoption of very\\nunsuccessful theories. Nevertheless, the said community might justify\\nits use of IWE by dint of the following reasoning: “Scientific\\ntheories tend to be hugely unsuccessful. These theories were arrived\\nat by application of IWE. That IWE is a reliable rule of\\ninference—that is, a rule of inference mostly leading from true\\npremises to true conclusions—is surely the worst explanation of\\nthe fact that our theories are so unsuccessful. Hence, by application\\nof IWE, we may conclude that IWE is a reliable rule of\\ninference.” While this would be an utterly absurd conclusion,\\nthe argument leading up to it cannot be convicted of being viciously\\ncircular anymore than Boyd’s argument for the reliability of\\nabduction can (if Psillos is right). It would appear, then, that there\\nmust be something else amiss with rule-circularity.',\n",
       "      '\\nIt is fair to note that for Psillos, the fact that a rule-circular\\nargument does not guarantee a positive conclusion about the rule at\\nissue is not sufficient for such an argument to be valid. A further\\nnecessary condition is “that one should not have reason to doubt\\nthe reliability of the rule—that there is nothing currently\\navailable which can make one distrust the rule” (Psillos 1999,\\n85). And there is plenty of reason to doubt the reliability of IWE; in\\nfact, the above argument supposes that it is unreliable. Two\\nquestions arise, however. First, why should we accept the additional\\ncondition? Second, do we really have no reason to doubt the\\nreliability of abduction? Certainly some of the abductive\\ninferences we make lead us to accept falsehoods. How many\\nfalsehoods may we accept on the basis of abduction before we can\\nlegitimately begin to distrust this rule? No clear answers have been\\ngiven to these questions.',\n",
       "      '\\nBe this as it may, even if rule-circularity is neither vicious nor\\notherwise problematic, one may still wonder how Boyd’s argument\\nis to convert a critic of abduction, given that it relies on\\nabduction. But Psillos makes it clear that the point of philosophical\\nargumentation is not always, and in any case need not be, to convince\\nan opponent of one’s position. Sometimes the point is, more\\nmodestly, to assure or reassure oneself that the position one\\nendorses, or is tempted to endorse, is correct. In the case at hand,\\nwe need not think of Boyd’s argument as an attempt to convince\\nthe opponent of abduction of its reliability. Rather, it may be\\nthought of as justifying the rule from within the perspective of\\nsomeone who is already sympathetic towards abduction; see Psillos 1999\\n(89).',\n",
       "      '\\nThere have also been attempts to argue for abduction in a more\\nstraightforward fashion, to wit, via enumerative induction. The common\\nidea of these attempts is that every newly recorded successful\\napplication of abduction—like the discovery of Neptune, whose\\nexistence had been postulated on explanatory grounds (see Section\\n1.2)—adds further support to the hypothesis that abduction is a\\nreliable rule of inference, in the way in which every newly observed\\nblack raven adds some support to the hypothesis that all ravens are\\nblack. Because it does not involve abductive reasoning, this type of\\nargument is more likely to also appeal to disbelievers in abduction.\\nSee Harré 1986, 1988, Bird 1998 (160), Kitcher 2001, and Douven\\n2002 for suggestions along these lines.'],\n",
       "     'subsection_title': '3.2 Defenses'}]},\n",
       "  {'main_content': ['\\nIn the past decade, Bayesian confirmation theory has firmly\\nestablished itself as the dominant view on confirmation; currently one\\ncannot very well discuss a confirmation-theoretic issue without making\\nclear whether, and if so why, one’s position on that issue\\ndeviates from standard Bayesian thinking. Abduction, in whichever\\nversion, assigns a confirmation-theoretic role to explanation:\\nexplanatory considerations contribute to making some hypotheses more\\ncredible, and others less so. By contrast, Bayesian confirmation\\ntheory makes no reference at all to the concept of explanation. Does\\nthis imply that abduction is at loggerheads with the prevailing\\ndoctrine in confirmation theory? Several authors have recently argued\\nthat not only is abduction compatible with Bayesianism, it is a\\nmuch-needed supplement to it. The so far fullest defense of this view\\nhas been given by Lipton (2004, Ch. 7); as he puts it, Bayesians\\nshould also be “explanationists” (his name for the\\nadvocates of abduction). (For other defenses, see Okasha 2000, McGrew\\n2003, Weisberg 2009, and Poston 2014, Ch. 7; for discussion, see Roche\\nand Sober 2013, 2014, and McCain and Poston 2014.)',\n",
       "    '\\nThis requires some clarification. For what could it mean for a\\nBayesian to be an explanationist? In order to apply Bayes’ rule\\nand determine the probability for H after learning E,\\nthe Bayesian agent will have to determine the probability of H\\nconditional on E. For that, he needs to assign unconditional\\nprobabilities to H and E as well as a probability to\\nE given H; the former two are mostly called “prior\\nprobabilities” (or just “priors”) of, respectively,\\nH and E, the latter the “likelihood” of\\nH on E. (This is the official Bayesian story. Not all of\\nthose who sympathize with Bayesianism adhere to that story. For\\ninstance, according to some it is more reasonable to think that\\nconditional probabilities are basic and that we derive unconditional\\nprobabilities from them; see Hájek 2003, and references\\ntherein.) How is the Bayesian to determine these values? As is well\\nknown, probability theory gives us more probabilities once we have\\nsome; it does not give us probabilities from scratch. Of course, when\\nH implies E or the negation of E, or when\\nH is a statistical hypothesis that bestows a certain chance on\\nE, then the likelihood follows “analytically.”\\n(This claim assumes some version of Lewis’ (1980) Principal\\nPrinciple, and it is controversial whether or not this principle is\\nanalytic; hence the scare quotes.) But this is not always the case,\\nand even if it were, there would still be the question of how to\\ndetermine the priors. This is where, according to Lipton, abduction\\ncomes in. In his proposal, Bayesians ought to determine their prior\\nprobabilities and, if applicable, likelihoods on the basis of\\nexplanatory considerations.',\n",
       "    '\\nExactly how are explanatory considerations to guide one’s choice\\nof priors? The answer to this question is not as simple as one might\\nat first think. Suppose you are considering what priors to assign to a\\ncollection of rival hypotheses and you wish to follow Lipton’s\\nsuggestion. How are you to do this? An obvious—though still\\nsomewhat vague—answer may seem to go like this: Whatever exact\\npriors you are going to assign, you should assign a higher one to the\\nhypothesis that explains the available data best than to any of its\\nrivals (provided there is a best explanation). Note, though, that your\\nneighbor, who is a Bayesian but thinks confirmation has nothing to do\\nwith explanation, may well assign a prior to the best explanation that\\nis even higher than the one you assign to that hypothesis. In fact,\\nhis priors for best explanations may even be consistently higher than\\nyours, not because in his view explanation is somehow related to\\nconfirmation—it is not, he thinks—but, well, just because.\\nIn this context, “just because” is a perfectly legitimate\\nreason, because any reason for fixing one’s priors counts as\\nlegitimate by Bayesian standards. According to mainstream Bayesian\\nepistemology, priors (and sometimes likelihoods) are up for grabs,\\nmeaning that one assignment of priors is as good as another, provided\\nboth are coherent (that is, they obey the axioms of probability\\ntheory). Lipton’s recommendation to the Bayesian to be an\\nexplanationist is meant to be entirely general. But what should your\\nneighbor do differently if he wants to follow the recommendation?\\nShould he give the same prior to any best explanation that you, his\\nexplanationist neighbor, give to it, that is, lower his\\npriors for best explanations? Or rather should he give even\\nhigher priors to best explanations than those he already\\ngives?',\n",
       "    '\\nPerhaps Lipton’s proposal is not intended to address those who\\nalready assign highest priors to best explanations, even if they do so\\non grounds that have nothing to do with explanation. The idea might be\\nthat, as long as one does assign highest priors to those hypotheses,\\neverything is fine, or at least finer than if one does not do so,\\nregardless of one’s reasons for assigning those priors. The\\nanswer to the question of how explanatory considerations are to guide\\none’s choice of priors would then presumably be that one ought\\nto assign a higher prior to the best explanation than to its rivals,\\nif this is not what one already does. If it is, one should just keep\\ndoing what one is doing.',\n",
       "    '\\n(As an aside, it should be noticed that, according to standard\\nBayesian usage, the term “priors” does not necessarily\\nrefer to the degrees of belief a person assigns before the receipt of\\nany data. If there are already data in, then, clearly, one\\nmay assign higher priors to hypotheses that best explain the\\nthen-available data. However, one can sensibly speak of “best\\nexplanations” even before any data are known. For example, one\\nhypothesis may be judged to be a better explanation than any of its\\nrivals because the former requires less complicated mathematics, or\\nbecause it is stated in terms of familiar concepts only, which is not\\ntrue of the others. More generally, such judgments may be based on\\nwhat Kosso (1992, 30) calls internal features of hypotheses\\nor theories, that is, features that “can be evaluated without\\nhaving to observe the world.”)',\n",
       "    '\\nA more interesting answer to the above question of how explanation is\\nto guide one’s choice of priors has been given by Jonathan\\nWeisberg (2009). We said that mainstream Bayesians regard one\\nassignment of prior probabilities as being as good as any other.\\nSo-called objective Bayesians do not do so, however. These Bayesians\\nthink priors must obey principles beyond the probability axioms in\\norder to be admissible. Objective Bayesians are divided among\\nthemselves over exactly which further principles are to be obeyed, but\\nat least for a while they agreed that the Principle of Indifference is\\namong them. Roughly stated, this principle counsels that, absent a\\nreason to the contrary, we give equal priors to competing hypotheses.\\nAs is well known, however, in its original form the Principle of\\nIndifference may lead to inconsistent assignments of probabilities and\\nso can hardly be advertised as a principle of rationality. The problem\\nis that there are typically various ways to partition logical space\\nthat appear plausible given the problem at hand, and that not all of\\nthem lead to the same prior probability assignment, even assuming the\\nPrinciple of Indifference. Weisberg’s proposal amounts to the\\nclaim that explanatory considerations may favor some of those\\npartitions over others. Perhaps we will not always end up with a\\nunique partition to which the Principle of Indifference is to be\\napplied, but it would already be progress if we ended up with only a\\nhandful of partitions. For we could then still arrive in a motivated\\nway at our prior probabilities, by proceeding in two steps, namely, by\\nfirst applying the Principle of Indifference to the partitions\\nseparately, thereby possibly obtaining different assignments of\\npriors, and by then taking a weighted average of the thus obtained\\npriors, where the weights, too, are to depend on explanatory\\nconsiderations. The result would again be a probability\\nfunction—the uniquely correct prior probability function,\\naccording to Weisberg.',\n",
       "    '\\nThe proposal is intriguing as far as it goes but, as Weisberg admits,\\nin its current form, it does not go very far. For one thing, it is\\nunclear how exactly explanatory considerations are to determine the\\nweights required for the second step of the proposal. For another, it\\nmay be idle to hope that taking explanatory considerations into\\naccount will in general leave us with a manageable set of partitions,\\nor that, even if it does, this will not be due merely to the fact that\\nwe are overlooking a great many prima facie plausible ways of\\npartitioning logical space to begin with. (The latter point echoes the\\nargument of the bad lot, of course.)',\n",
       "    '\\nAnother suggestion about the connection between abduction and Bayesian\\nreasoning—to be found in Okasha 2000, McGrew 2003, Lipton 2004\\n(Ch. 7), and Dellsén 2018—is that the explanatory\\nconsiderations may serve as a heuristic to determine, even if only\\nroughly, priors and likelihoods in cases in which we would otherwise\\nbe clueless and could do no better than guessing. This suggestion is\\nsensitive to the well-recognized fact that we are not always able to\\nassign a prior to every hypothesis of interest, or to say how probable\\na given piece of evidence is conditional on a given hypothesis.\\nConsideration of that hypothesis’ explanatory power might then\\nhelp us to figure out, if perhaps only within certain bounds, what\\nprior to assign to it, or what likelihood to assign to it on the given\\nevidence.',\n",
       "    '\\nBayesians, especially the more modest ones, might want to retort that\\nthe Bayesian procedure is to be followed if, and only if, either (a)\\npriors and likelihoods can be determined with some precision and\\nobjectivity, or (b) likelihoods can be determined with some precision\\nand priors can be expected to “wash out” as more and more\\nevidence accumulates, or (c) priors and likelihoods can both be\\nexpected to wash out. In the remaining cases—they might\\nsay—we should simply refrain from applying Bayesian reasoning. A\\nfortiori, then, there is no need for an abduction-enhanced Bayesianism\\nin these cases. And some incontrovertible mathematical results\\nindicate that, in the cases that fall under (a), (b), or (c), our\\nprobabilities will converge to the truth anyhow. Consequently, in\\nthose cases there is no need for the kind of abductive heuristics that\\nthe above-mentioned authors suggest, either. (Weisberg 2009, Sect.\\n3.2, raises similar concerns.)',\n",
       "    '\\nPsillos (2000) proposes yet another way in which abduction might\\nsupplement Bayesian confirmation theory, one that is very much in the\\nspirit of Peirce’s conception of abduction. The idea is that\\nabduction may assist us in selecting plausible candidates for testing,\\nwhere the actual testing then is to follow Bayesian lines. However,\\nPsillos concedes (2004) that this proposal assigns a role to abduction\\nthat will strike committed explanationists as being too limited.',\n",
       "    '\\nFinally, a possibility that has so far not been considered in the\\nliterature is that abduction and Bayesianism do not so much work in\\ntandem—as they do on the above proposals—as operate in\\ndifferent modes of reasoning; the Bayesian and the explanationist are\\ncharacters that feature in different plays, so to speak. It is widely\\naccepted that sometimes we speak and think about our beliefs in a\\ncategorical manner, while at other times we speak and think about them\\nin a graded way. It is far from clear how these different ways of\\nspeaking and thinking about beliefs—the epistemology of belief\\nand the epistemology of degrees of belief, to use Richard\\nFoley’s (1992) terminology—are related to one another. In\\nfact, it is an open question whether there is any straightforward\\nconnection between the two, or even whether there is a connection at\\nall. Be that as it may, given that the distinction is undeniable, it\\nis a plausible suggestion that, just as there are different ways of\\ntalking and thinking about beliefs, there are different ways of\\ntalking and thinking about the revision of beliefs. In\\nparticular, abduction could well have its home in the epistemology of\\nbelief, and be called upon whenever we reason about our beliefs in a\\ncategorical mode, while at the same time Bayes’ rule could have\\nits home in the epistemology of degrees of belief. Hard-nosed\\nBayesians may insist that whatever reasoning goes on in the\\ncategorical mode must eventually be justifiable in Bayesian terms, but\\nthis presupposes the existence of bridge principles connecting the\\nepistemology of belief with the epistemology of degrees of\\nbelief—and, as mentioned, whether such principles exist is\\npresently unclear.'],\n",
       "   'section_title': '4. Abduction versus Bayesian Confirmation Theory',\n",
       "   'subsections': []}],\n",
       " 'bibliography': ['Achinstein, P., 2001. The Book of Evidence, Oxford:\\nOxford University Press.',\n",
       "  'Adler, J., 1994. “Testimony, Trust, Knowing,”\\nJournal of Philosophy, 91: 264–275.',\n",
       "  'Bach, K. and Harnish, R., 1979. Linguistic Communication and\\nSpeech Acts, Cambridge MA: MIT Press.',\n",
       "  'Bird, A., 1998. Philosophy of Science, London: UCL\\nPress.',\n",
       "  'Bigelow, J., 2010. “Quine, Mereology, and Inference to the\\nBest Explanation,” Logique et Analyse, 212:\\n465–482.',\n",
       "  'Bovens, L. and Hartmann, S., 2003. “Solving the Riddle of\\nCoherence,” Mind, 112: 601–633.',\n",
       "  'Boyd, R., 1981. “Scientific Realism and Naturalistic\\nEpistemology,” in P. Asquith and R. Giere (eds.), PSA\\n1980, (vol. II), East Lansing MI: Philosophy of Science\\nAssociation, pp. 613–662.',\n",
       "  '–––, 1984. “The Current Status of\\nScientific Realism,” in J. Leplin (ed.), Scientific\\nRealism, Berkeley CA: University of California Press, pp.\\n41–82.',\n",
       "  '–––, 1985. “Lex Orandi est Lex\\nCredendi,” in P. Churchland and C. Hooker (eds.), Images of\\nScience, Chicago IL: University of Chicago Press, pp.\\n3–34.',\n",
       "  'Brem, S. and Rips, L. J., 2000. “Explanation and Evidence in\\nInformal Argument,” Cognitive Science, 24:\\n573–604.',\n",
       "  'Callebaut, W. (ed.), 1993. Taking the Naturalistic Turn,\\nChicago IL: University of Chicago Press.',\n",
       "  'Campos, D., 2011. “On the Distinction Between Peirce’s\\nAbduction and Lipton’s Inference to the Best Explanation,”\\nSynthese, 180: 419–442.',\n",
       "  'Climenhaga, N., forthcoming. “Inference to the Best\\nExplanation Made Incoherent,” Journal of Philosophy,\\n preprint available online.',\n",
       "  'Dascal, M., 1979. “Conversational Relevance,” in A.\\nMargalit (ed.), Meaning and Use, Dordrecht: Reidel, pp.\\n153–174.',\n",
       "  'Dellsén, F., 2017. “Reactionary Responses to the Bad\\nLot Objection,” Studies in History and Philosophy of\\nScience, 61: 32–40.',\n",
       "  '–––, 2018. “The Heuristic Conception of\\nInference to the Best Explanation,”\\nPhilosophical Studies, 175: 1745–1766. ',\n",
       "  'Douven, I., 1999. “Inference to the Best Explanation Made\\nCoherent,” Philosophy, of Science, 66:\\nS424–S435.',\n",
       "  '–––, 2002. “Testing Inference to the Best\\nExplanation,” Synthese, 130: 355–377.',\n",
       "  '–––, 2008. “Underdetermination,” in\\nS. Psillos and M. Curd (eds.), The Routledge Companion to the\\nPhilosophy of Science, London: Routledge, pp. 292–301.',\n",
       "  '–––, 2013. “Inference to the Best\\nExplanation, Dutch Books, and Inaccuracy Minimisation,”\\nPhilosophical Quarterly, 63: 428–444.',\n",
       "  '–––, 2016a. The Epistemology of Indicative\\nConditionals, Cambridge: Cambridge University Press.',\n",
       "  '–––, 2016b. “Explanation, Updating, and\\nAccuracy,” Journal of Cognitive Psychology, 28:\\n1004–1012.',\n",
       "  '–––, 2017. “What Is Inference to the Best\\nExplanation? And Why Should We Care?” in T. Poston and K. McCain\\n(eds.), Best Explanations: New Essays on Inference to the Best\\nExplanation, Oxford: Oxford University Press, pp.\\n4–22.',\n",
       "  '–––, 2020. “The Ecological Rationality of\\nExplanatory Reasoning,” Studies in History and Philosophy of\\nScience, 79: 1–14.',\n",
       "  '–––, forthcoming. The Art of\\nAbduction, Cambridge MA: MIT Press.',\n",
       "  'Douven, I. and Mirabile, P., 2018. “Best, Second-best, and\\nGood-enough Explanations: How They Matter to Reasoning,”\\nJournal of Experimental Psychology: Language, Memory, and\\nCognition, 44: 1792–1813.',\n",
       "  'Douven, I. and Schupbach, J., 2015a. “The Role of\\nExplanatory Considerations in Updating,” Cognition,\\n142: 299–311.',\n",
       "  '–––, 2015b. “Probabilistic Alternatives to\\nBayesianism: The Case of Explanationism,” Frontiers in\\nPsychology, 6: 459. doi:10.3389/fpsyg.2015.00459',\n",
       "  'Douven, I. and Wenmackers, S., 2017. “Inference to the Best\\nExplanation versus Bayes’s Rule in a Social Setting,”\\nBritish Journal for the Philosophy of Science, 68:\\n535–570.',\n",
       "  'Dragulinescu, S., 2016. “Inference to the Best Explanation\\nand Mechanisms in Medicine,” Theoretical Medicine and\\nBioethics, 37(3): 211–232.',\n",
       "  'Fann, K. T., 1970. Peirce’s Theory of Abduction,\\nThe Hague: Martinus Nijhoff.',\n",
       "  'Fine, A., 1984. “The Natural Ontological Attitude,” in\\nJ. Leplin (ed.), Scientific Realism, Berkeley CA: University\\nof California Press, pp. 83–107.',\n",
       "  'Foley, R., 1992. “The Epistemology of Belief and the\\nEpistemology of Degrees of Belief,” American Philosophical\\nQuarterly, 29: 111–124.',\n",
       "  'Folina, J., 2016. “Realism, Skepticism, and the Brain in a\\nVat,” in S. Goldberg (ed.), The Brain in a Vat,\\nCambridge: Cambridge University Press, pp. 155–173.',\n",
       "  'Forster, M. and Sober, E., 1994. “How to Tell when Simpler,\\nMore Unified, or Less Ad Hoc, Theories will Provide More\\nAccurate Predictions,” British Journal for the Philosophy of\\nScience, 45: 1–36.',\n",
       "  'Frankfurt, H., 1958. “Peirce’s Notion of\\nAbduction,” Journal of Philosophy, 55:\\n593–596.',\n",
       "  'Fricker, E., 1994. “Against Gullibility,” in B. K.\\nMatilal and A. Chakrabarti (eds.), Knowing from Words,\\nDordrecht: Kluwer, pp. 125–161.',\n",
       "  'Goldman, A., 1988. Empirical Knowledge, Berkeley CA:\\nUniversity of California Press.',\n",
       "  'Hájek, A., 2003. “What Conditional Probability Could\\nNot Be,” Synthese, 137: 273–323.',\n",
       "  'Harman, G., 1965. “The Inference to the Best\\nExplanation,” Philosophical Review, 74:\\n88–95.',\n",
       "  '–––, 1973. Thought, Princeton NJ:\\nPrinceton University Press.',\n",
       "  '–––, 1997. “Pragmatism and Reasons for\\nBelief,” in C. Kulp (ed.), Realism/Antirealism and\\nEpistemology, Totowa NJ: Rowman and Littlefield, pp.\\n123–147.',\n",
       "  'Harré, R., 1986. Varieties of Realism, Oxford:\\nBlackwell.',\n",
       "  '–––, 1988. “Realism and Ontology,”\\nPhilosophia Naturalis, 25: 386–398.',\n",
       "  'Hobbs, J. R., 2004. “Abduction in Natural Language\\nUnderstanding,” in L. Horn and G. Ward (eds.), The Handbook\\nof Pragmatics, Oxford: Blackwell, pp. 724–741.',\n",
       "  'Janssen, M., 2002. “Reconsidering a Scientific Revolution:\\nThe Case of Einstein versus, Lorentz,” Physics in\\nPerspective, 4: 421–446.',\n",
       "  'Josephson, J. R. and Josephson, S. G. (eds.), 1994. Abductive\\nInference, Cambridge: Cambridge University Press.',\n",
       "  'Kitcher, P., 2001. “Real Realism: The Galilean\\nStrategy,” Philosophical Review, 110:\\n151–197.',\n",
       "  'Koehler, D. J., 1991. “Explanation, Imagination, and\\nConfidence in Judgment,” Psychological Bulletin, 110:\\n499–519.',\n",
       "  'Koslowski, B., Marasia, J., Chelenza, M., and Dublin, R., 2008.\\n“Information Becomes Evidence when an Explanation Can\\nIncorporate it into a Causal Framework,” Cognitive\\nDevelopment, 23: 472–487.',\n",
       "  'Kosso, P., 1992. Reading the Book of Nature, Cambridge:\\nCambridge University Press.',\n",
       "  'Krzyżanowska, K, Wenmackers, S., and Douven, I., 2014.\\n“Rethinking Gibbard’s Riverboat Argument,”\\nStudia Logica, 102: 771–792.',\n",
       "  'Kuipers, T., 1984. “Approaching the Truth with the Rule of\\nSuccess,” Philosophia, Naturalis, 21:\\n244–253.',\n",
       "  '–––, 1992. “Naive and Refined Truth\\nApproximation,” Synthese, 93: 299–341.',\n",
       "  '–––, 2000. From Instrumentalism to\\nConstructive Realism, Dordrecht: Kluwer.',\n",
       "  'Kvanvig, J., 1994. “A Critique of van Fraassen’s\\nVoluntaristic Epistemology,” Synthese, 98:\\n325–348.',\n",
       "  'Kyburg Jr., H., 1990. Science and Reason, Oxford: Oxford\\nUniversity Press.',\n",
       "  'Laudan, L., 1981. “A Confutation of Convergent\\nRealism,” Philosophy of Science, 48: 19–49.',\n",
       "  'Lewis, D., 1980. “A Subjectivist’s Guide to Objective\\nChance,” in R. Jeffrey (ed.), Studies in Inductive Logic and\\nProbability, Berkeley CA: University of California Press, pp.\\n263–293.',\n",
       "  'Li, M. and Vitanyi, P., 1997. An Introduction to Kolmogorov\\nComplexity and its Applications, New York: Springer.',\n",
       "  'Lipton, P., 1991. Inference to the Best Explanation,\\nLondon: Routledge.',\n",
       "  '–––, 1993. “Is the Best Good\\nEnough?” Proceedings of the Aristotelian Society, 93:\\n89–104.',\n",
       "  '–––, 1998. “The Epistemology of\\nTestimony,” Studies in History and Philosophy of\\nScience, 29: 1–31.',\n",
       "  '–––, 2004. Inference to the Best\\nExplanation, (2nd ed.), London: Routledge.',\n",
       "  'Lombrozo, T., 2007. “Simplicity and Probability in Causal\\nExplanation,” Cognitive Psychology, 55:\\n232–257.',\n",
       "  '–––, 2012. “Explanation and Abductive\\nInference,” in K. Holyoak and R. Morrison (eds.), Oxford\\nHandbook of Thinking and Reasoning, Oxford: Oxford University\\nPress, pp. 260–276.',\n",
       "  '–––, 2016. “Explanatory Preferences Shape\\nLearning and Inference,” Trends in Cognitive Sciences,\\n20: 748–759.',\n",
       "  'Lombrozo, T. and Gwynne, N. Z., 2014. “Explanation and\\nInference: Mechanistic and Functional Explanations Guide Property\\nGeneralization,” Frontiers in Human Neuroscience, 8.\\ndoi:10.3389/fnhum.2014.00700',\n",
       "  'Maher, P., 1992. “Diachronic Rationality,”\\nPhilosophy of Science, 59: 120–141.',\n",
       "  'McAuliffe, W., 2015. “How Did Abduction Get Confused with\\nInference to the Best Explanation?” Transactions of the\\nCharles S. Peirce Society, 51: 300–319.',\n",
       "  'McCain, K. and Poston, T., 2014. “Why Explanatoriness is\\nEvidentially Relevant,” Thought, 3: 145–153.',\n",
       "  'McGrew, T., 2003. “Confirmation, Heuristics, and Explanatory\\nReasoning,” British Journal for the Philosophy of\\nScience, 54: 553–567.',\n",
       "  'McMullin, E., 1992. The Inference that Makes Science,\\nMilwaukee WI: Marquette University Press.',\n",
       "  '–––, 1996. “Epistemic Virtue and Theory\\nAppraisal,” in I. Douven and L. Horsten (eds.), Realism in\\nthe Sciences, Leuven: Leuven University Press, pp.\\n13–34.',\n",
       "  'Moore, G. E., 1962. “Proof of an External World,” in\\nhis Philosophical Papers, New York: Collier Books, pp.\\n126–149.',\n",
       "  'Moser, P., 1989. Knowledge and Evidence, Cambridge:\\nCambridge University Press.',\n",
       "  'Musgrave, A., 1988. “The Ultimate Argument for Scientific\\nRealism,” in R. Nola (ed.), Relativism and Realism in\\nScience, Dordrecht: Kluwer, pp. 229–252.',\n",
       "  'Niiniluoto, I., 1998. “Verisimilitude: The Third\\nPeriod,” British Journal for the Philosophy of Science,\\n49: 1–29.',\n",
       "  '–––, 1999. “Defending Abduction,”\\nPhilosophy of Science, 66: S436–S451.',\n",
       "  'Okasha, S., 2000. “Van Fraassen’s Critique of\\nInference to the Best Explanation,” Studies in History and\\nPhilosophy of Science, 31: 691–710.',\n",
       "  'Olsson, E., 2005. Against Coherence, Oxford: Oxford\\nUniversity Press.',\n",
       "  'Pargetter, R., 1984. “The Scientific Inference to Other\\nMinds,” Australasian Journal of Philosophy, 62:\\n158–163.',\n",
       "  'Peirce, C. S. [CP]. Collected Papers of Charles Sanders\\nPeirce, edited by C. Hartshorne, P. Weiss, and A. Burks,\\n1931–1958, Cambridge MA: Harvard University Press.',\n",
       "  'Poston, T., 2014. Reason and Explanation, Basingstoke:\\nPalgrave Macmillan.',\n",
       "  'Psillos, S., 1999. Scientific Realism: How Science Tracks\\nTruth, London: Routledge.',\n",
       "  '–––, 2000. “Abduction: Between Conceptual\\nRichness and Computational Complexity,” in A. K. Kakas and P.\\nFlach (eds.), Abduction and Induction: Essays on their Relation\\nand Integration, Dordrecht: Kluwer, pp. 59–74.',\n",
       "  '–––, 2004. “Inference to the Best\\nExplanation and Bayesianism,” in F. Stadler (ed.), Induction\\nand Deduction in the Sciences, Dordrecht: Kluwer, pp.\\n83–91.',\n",
       "  'Putnam, H., 1981. Reason, Truth and History, Cambridge:\\nCambridge University Press.',\n",
       "  'Roche, W. and Sober, E., 2013. “Explanatoriness is\\nEvidentially Irrelevant, or Inference to the Best Explanation Meets\\nBayesian Confirmation Theory,” Analysis, 73:\\n659–668',\n",
       "  '–––, 2014. “Explanatoriness and Evidence:\\nA Reply to McCain and Poston,” Thought, 3:\\n193–199.',\n",
       "  'Russell, B., 1912. The Problems of Philosophy, Oxford:\\nOxford University Press.',\n",
       "  'Schupbach, J., 2014. “Is the Bad Lot Objection Just\\nMisguided?” Erkenntnis, 79: 55–64.',\n",
       "  'Schupbach, J. and Sprenger, J., 2011. “The Logic of\\nExplanatory Power,” Philosophy of Science, 78:\\n105–127.',\n",
       "  'Schurz, G., 2008. “Patterns of Abduction,”\\nSynthese, 164: 201–234.',\n",
       "  'Shalkowski, S., 2010. “IBE, GMR, and Metaphysical\\nProjects,” in B. Hale and A. Hoffmann (eds.), Modality:\\nMetaphysics, Logic, and Epistemology, Oxford: Oxford University\\nPress, pp. 169–187.',\n",
       "  'Skyrms, B., 1993. “A Mistake in Dynamic Coherence\\nArguments?” Philosophy of Science, 60:\\n320–328.',\n",
       "  'Sloman, S., 1994. “When Explanations Compete: The Role of\\nExplanatory Coherence on Judgments of Likelihood,”\\nCognition, 52: 1–21.',\n",
       "  'Sober, E., 2015. Ockham’s Razor: A User’s\\nManual, Cambridge: Cambridge University Press.',\n",
       "  'Stanford, K., 2009. “Underdetermination of Scientific\\nTheory,” in Stanford Encyclopedia of Philosophy (Winter\\n2009 Edition), Edward N. Zalta (ed.), URL =\\n <https://plato.stanford.edu/archives/win2009/entries/scientific-underdetermination/>.',\n",
       "  'Teller, P., 1973. “Conditionalization and\\nObservation,” Synthese, 26: 218–258.',\n",
       "  'Thagard, P., 1978. “The Best Explanation: Criteria for\\nTheory Choice,” Journal of Philosophy, 75:\\n76–92.',\n",
       "  'van Fraassen, B., 1980. The Scientific Image, Oxford:\\nOxford University Press.',\n",
       "  '–––, 1983. “Glymour on Evidence and\\nExplanation,” in J. Earman (ed.), Testing Scientific\\nTheories, Minneapolis: University of Minnesota Press, pp.\\n165–176.',\n",
       "  '–––, 1985. “Empiricism in the Philosophy\\nof Science,” in P. Churchland and C. Hooker (eds.), Images\\nof Science, Chicago IL: University of Chicago Press, pp.\\n245–308.',\n",
       "  '–––, 1989. Laws and Symmetry, Oxford:\\nOxford University Press.',\n",
       "  'Vogel, J., 1990. “Cartesian Skepticism and Inference to the\\nBest Explanation,” Journal of Philosophy, 87:\\n658–666.',\n",
       "  '–––, 2005. “The Refutation of\\nSkepticism,” in M. Steup and E. Sosa (eds.), Contemporary\\nDebates in Epistemology, Oxford: Blackwell Publishing, pp.\\n72–84.',\n",
       "  'Weintraub, R., 2013. “Induction and Inference to the Best\\nExplanation,” Philosophical Studies, 166:\\n203–216.',\n",
       "  'Weisberg, J., 2009. “Locating IBE in the Bayesian\\nFramework,” Synthese, 167: 125–143.',\n",
       "  'Williams, J. and Lombrozo, T., 2010. “The Role of\\nExplanation in Discovery and Generalization: Evidence from Category\\nLearning,” Cognitive Science, 34: 776–806.',\n",
       "  'Williamson, T., 2017. “Semantic Paradoxes and Abductive\\nMethodology,” in B. Armour-Garb (ed.),\\nReflections on the Liar, Oxford: Oxford University\\nPress, pp. 325–346.'],\n",
       " 'related_entries': [{'href': '../epistemology-bayesian/',\n",
       "   'text': 'epistemology: Bayesian'},\n",
       "  {'href': '../induction-problem/', 'text': 'induction: problem of'},\n",
       "  {'href': '../peirce/', 'text': 'Peirce, Charles Sanders'},\n",
       "  {'href': '../scientific-explanation/', 'text': 'scientific explanation'},\n",
       "  {'href': '../scientific-realism/', 'text': 'scientific realism'},\n",
       "  {'href': '../simplicity/', 'text': 'simplicity'},\n",
       "  {'href': '../skepticism/', 'text': 'skepticism'},\n",
       "  {'href': '../scientific-underdetermination/',\n",
       "   'text': 'underdetermination, of scientific theories'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_article = dataset_subset[0]\n",
    "example_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861d1cf-7a08-467d-a035-6f113c1a7e6d",
   "metadata": {},
   "source": [
    "# Prepare dataset: chuncking, add metadata, get embeddings\n",
    "\n",
    "* To effectively search by philosophical concepts or philosophers, you need to classify the articles in the dataset into categories. Each article should be tagged with key terms, philosophical schools, or specific philosophers.\n",
    "* To organize proper navigation through the articles, you can include this information in the search index (add headings to metadata for quick search by sections).\n",
    "\n",
    "`TODO`for adding philosophical schools to metadata, you may need a dictionary search (\"The Dictionary of Philosophy\" или \"The Cambridge Dictionary of Philosophy\", Wikipedia: \"Philosophical Schools\"/\"Philosophical Terms\"). Because it's working bad: \n",
    "```python\n",
    "elif ent.label_ in [\"ORG\", \"NORP\", \"LANGUAGE\"]:  # Organizations and religious/political groups\n",
    "   concepts.add(ent.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a3e28e-58bc-4e0a-99ad-b0170ddd6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "import hashlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c22ad11-6f4e-46c3-b5db-0936c4432ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa90c6f-0e73-4bfb-935b-2ff3e9418cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "# Load spaCy model for named entity recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af692c4-ca8b-44ba-8753-79703f1f50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity recognition and chunking\n",
    "class PhilosophyDataProcessor:\n",
    "    def extract_entities(self, text: str) -> tuple:\n",
    "        doc = nlp(text)\n",
    "        philosophers = set()\n",
    "        concepts = set()\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                philosophers.add(ent.text)\n",
    "            elif ent.label_ in [\"ORG\", \"NORP\", \"LANGUAGE\"]:  # Organizations and religious/political groups\n",
    "                concepts.add(ent.text)\n",
    "        \n",
    "        return list(philosophers), list(concepts)\n",
    "\n",
    "    def create_chunk_id(self, text: str, article_title: str, chunk_type: str) -> str:\n",
    "        # Create a unique identifier for the chunk\n",
    "        content = f\"{text}{article_title}{chunk_type}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()\n",
    "\n",
    "    def process_article(self, article: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        chunks = []\n",
    "        \n",
    "        # Process preamble\n",
    "        preamble_text = ' '.join(article['preamble'])\n",
    "        philosophers, concepts = self.extract_entities(preamble_text)\n",
    "        \n",
    "        # Create full article chunk\n",
    "        full_article_text = preamble_text\n",
    "        for section in article['main_text']:\n",
    "            section_text = ' '.join(section['main_content'])\n",
    "            full_article_text += ' ' + section_text\n",
    "        \n",
    "        full_article_chunk = {\n",
    "            'chunk_id': self.create_chunk_id(full_article_text, article['title'], 'full_article'),\n",
    "            'article_title': article['title'],\n",
    "            'section_path': [],\n",
    "            'chunk_type': 'full_article',\n",
    "            'philosophers': philosophers,\n",
    "            'concepts': concepts,\n",
    "            'content': full_article_text\n",
    "        }\n",
    "        chunks.append(full_article_chunk)\n",
    "        \n",
    "        # Process sections\n",
    "        for section in article['main_text']:\n",
    "            section_text = ' '.join(section['main_content'])\n",
    "            section_philosophers, section_concepts = self.extract_entities(section_text)\n",
    "            \n",
    "            section_chunk = {\n",
    "                'chunk_id': self.create_chunk_id(section_text, article['title'], 'section'),\n",
    "                'article_title': article['title'],\n",
    "                'section_path': [section['section_title']],\n",
    "                'chunk_type': 'section',\n",
    "                'philosophers': list(set(philosophers + section_philosophers)),\n",
    "                'concepts': list(set(concepts + section_concepts)),\n",
    "                'content': section_text\n",
    "            }\n",
    "            chunks.append(section_chunk)\n",
    "            \n",
    "            # Process paragraphs\n",
    "            for paragraph in section['main_content']:\n",
    "                if len(paragraph.split()) > 20:  \n",
    "                    para_philosophers, para_concepts = self.extract_entities(paragraph)\n",
    "                    \n",
    "                    paragraph_chunk = {\n",
    "                        'chunk_id': self.create_chunk_id(paragraph, article['title'], 'paragraph'),\n",
    "                        'article_title': article['title'],\n",
    "                        'section_path': [section['section_title']],\n",
    "                        'chunk_type': 'paragraph',\n",
    "                        'philosophers': list(set(philosophers + section_philosophers + para_philosophers)),\n",
    "                        'concepts': list(set(concepts + section_concepts + para_concepts)),\n",
    "                        'content': paragraph\n",
    "                    }\n",
    "                    chunks.append(paragraph_chunk)\n",
    "\n",
    "            # Process subsections\n",
    "            for subsection in section.get('subsections', []):\n",
    "                subsection_text = ' '.join(subsection['content'])\n",
    "                subsection_philosophers, subsection_concepts = self.extract_entities(subsection_text)\n",
    "                \n",
    "                subsection_chunk = {\n",
    "                    'chunk_id': self.create_chunk_id(subsection_text, article['title'], 'subsection'),\n",
    "                    'article_title': article['title'],\n",
    "                    'section_path': [section['section_title'], subsection['subsection_title']],\n",
    "                    'chunk_type': 'subsection',\n",
    "                    'philosophers': list(set(philosophers + section_philosophers + subsection_philosophers)),\n",
    "                    'concepts': list(set(concepts + section_concepts + subsection_concepts)),\n",
    "                    'content': subsection_text\n",
    "                }\n",
    "                chunks.append(subsection_chunk)\n",
    "        return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbaa2d1d-e0e7-4362-98da-ab17030127f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = PhilosophyDataProcessor()\n",
    "\n",
    "# Process one article as an example\n",
    "example_article = dataset_subset[0]\n",
    "chunks = processor.process_article(example_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6deb789d-bfe8-4b1d-9d7a-5a033ffce2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>section_path</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>philosophers</th>\n",
       "      <th>concepts</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92dd2f6b5d033c12efb2f8ee3047601e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[]</td>\n",
       "      <td>full_article</td>\n",
       "      <td>[Charles Sanders\\nPeirce]</td>\n",
       "      <td>[Inference]</td>\n",
       "      <td>\\nIn the philosophical literature, the term “a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3b5103db83e97338eb7270a86a63c65</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>section</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81e573a9d329de10a9651c19c4907dc2</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1738ba0482fa09f893136ec9e10ebff5</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nOne morning you enter the kitchen to find a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34bf01c649b729cd3d740f4d5a7cdadf</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nWalking along the beach, you see what looks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>501b7b05cb58454829b17faa1ca0b67f</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nIn these examples, the conclusions do not fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6c943762de83a112fe91d3de929913e8</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea, 1.1 Deduction...</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Louise, Tim, Harman, Harry’s, John, Bs, Harry...</td>\n",
       "      <td>[Winston\\nChurchill, Hilary Putnam’s, Dutch, I...</td>\n",
       "      <td>\\nAbduction is normally thought of as being on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>806563744b1ad2c6fdc20c84694a9061</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea, 1.2 The ubiqu...</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Josephson, Harman, Harry’s, Pargetter 1984, P...</td>\n",
       "      <td>[Dascal, Thomson, Stanford, Goldman, Winston\\n...</td>\n",
       "      <td>\\nThe type of inference exemplified in the cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2e6cd6b7abb9bc8faf2847668c92552a</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>section</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nPrecise statements of what abduction amounts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fb65974393a7620588b7c530d53e9082</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nPrecise statements of what abduction amounts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8499745946def21e570ae45e9a8b2a82</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nIn textbooks on epistemology or the philosop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1a750c640ab45d4dafc37540fd941b76</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nAn observation that is frequently made about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2bd101c6a5154c559d90b59afe196a2e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nFurthermore, many of those who think ABD1 is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4f3f89d39f6e17a689d244cf3c1f8db4</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nThe real problem with ABD1 runs deeper than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1c4c184c0ddd0f96760e6fb93aa319fc</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nHow reasonable is it to suppose that this ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f7ecd1a32026e385eb2478522b11f166</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nIn response to this, one might argue that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10df8e48bc88212af4767ab5bb2cc362</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nAlas, there is a catch. For even though ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>169088bc3b24a5b29621bf52c9a4b680</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nA more promising response to the above “argu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7b955e4553c4bf8f4ff01e2f394ae4b5</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nThe first option is to modify the rule so as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a769e7233c923d5482ef84a18d34e322</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nNeedless to say, ABD2 needs supplementing by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c8927e679629bd82151236f34dcb5f8e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nSecondly, one can formulate a symmetric or c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>209998281eac41cd3e3b55194219adaa</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nClearly, ABD3 requires an account of closene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bd8a142a8ae7d7250e4723f684d50b64</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nOne noteworthy feature of the congruous vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bb0345399a3ea255e6d31f230e818d53</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nAs mentioned, there is widespread agreement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c9249aa1fd1ac7dc1b7b71164a3de79d</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[2. Explicating Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Douven, Koslowski, Williams, Patricia Mirabil...</td>\n",
       "      <td>[Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...</td>\n",
       "      <td>\\nWith respect to the normative question of wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bb09ab0b5a7f2dd68c1057691287d985</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[3. The Status of Abduction]</td>\n",
       "      <td>section</td>\n",
       "      <td>[Koehler, Charles Sanders\\nPeirce, Brem, Lombr...</td>\n",
       "      <td>[Lombrozo’s, Bayesian, Inference]</td>\n",
       "      <td>\\nEven if it is true that we routinely rely on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6ae1afd1662837a0294f1ac43b46c62c</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[3. The Status of Abduction]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Koehler, Charles Sanders\\nPeirce, Brem, Lombr...</td>\n",
       "      <td>[Lombrozo’s, Bayesian, Inference]</td>\n",
       "      <td>\\nEven if it is true that we routinely rely on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>69da7307a5a7eb89d8c73a877841e42e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[3. The Status of Abduction, 3.1 Criticisms]</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Koehler, van Fraassen’s, van Fraassen\\n1989, ...</td>\n",
       "      <td>[Bayesian, Lorentz, Dutch, Bayes, Inference, L...</td>\n",
       "      <td>\\nWe have already encountered the so-called ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>603011c48c8bfc490ae806a1ba1b143c</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[3. The Status of Abduction, 3.2 Defenses]</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Koehler, Douven, Psillos, Lombrozo, Boyd 1981...</td>\n",
       "      <td>[Bayesian, See Harré, Inference, Lombrozo’s, N...</td>\n",
       "      <td>\\nHardly anyone nowadays would want to subscri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9f6b5d5c458131ee8547cc2b36012efd</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>section</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nIn the past decade, Bayesian confirmation th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>e429fb5c3e2a99a629105f9237b66a2d</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nIn the past decade, Bayesian confirmation th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>d9e78e99955c0b0ae1dc121c3099336d</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nThis requires some clarification. For what c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>489106242e16717e1276835ca38b25f9</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nExactly how are explanatory considerations t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>025cb383324ec21cd8cb553cf1a8f8f9</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nPerhaps Lipton’s proposal is not intended to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17ed98678b554b569ba01d9dce117a44</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\n(As an aside, it should be noticed that, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>944b677a84a379e8805518f72011e74c</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nA more interesting answer to the above quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5238179758572338829937c7dda59f32</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nThe proposal is intriguing as far as it goes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>d5e38b1922a893a6d1b887c9ea7a6c27</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nAnother suggestion about the connection betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5d84563da86fea01adfe1235cd360bdd</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nBayesians, especially the more modest ones, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>337d80c564b6a3ca35e08b80301661b8</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nPsillos (2000) proposes yet another way in w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2534a5a8ae83a361431b01c8e721d944</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[4. Abduction versus Bayesian Confirmation The...</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...</td>\n",
       "      <td>[Bayesian, Poston 2014, Lipton, Bayesians, Pei...</td>\n",
       "      <td>\\nFinally, a possibility that has so far not b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chunk_id article_title  \\\n",
       "0   92dd2f6b5d033c12efb2f8ee3047601e     Abduction   \n",
       "1   a3b5103db83e97338eb7270a86a63c65     Abduction   \n",
       "2   81e573a9d329de10a9651c19c4907dc2     Abduction   \n",
       "3   1738ba0482fa09f893136ec9e10ebff5     Abduction   \n",
       "4   34bf01c649b729cd3d740f4d5a7cdadf     Abduction   \n",
       "5   501b7b05cb58454829b17faa1ca0b67f     Abduction   \n",
       "6   6c943762de83a112fe91d3de929913e8     Abduction   \n",
       "7   806563744b1ad2c6fdc20c84694a9061     Abduction   \n",
       "8   2e6cd6b7abb9bc8faf2847668c92552a     Abduction   \n",
       "9   fb65974393a7620588b7c530d53e9082     Abduction   \n",
       "10  8499745946def21e570ae45e9a8b2a82     Abduction   \n",
       "11  1a750c640ab45d4dafc37540fd941b76     Abduction   \n",
       "12  2bd101c6a5154c559d90b59afe196a2e     Abduction   \n",
       "13  4f3f89d39f6e17a689d244cf3c1f8db4     Abduction   \n",
       "14  1c4c184c0ddd0f96760e6fb93aa319fc     Abduction   \n",
       "15  f7ecd1a32026e385eb2478522b11f166     Abduction   \n",
       "16  10df8e48bc88212af4767ab5bb2cc362     Abduction   \n",
       "17  169088bc3b24a5b29621bf52c9a4b680     Abduction   \n",
       "18  7b955e4553c4bf8f4ff01e2f394ae4b5     Abduction   \n",
       "19  a769e7233c923d5482ef84a18d34e322     Abduction   \n",
       "20  c8927e679629bd82151236f34dcb5f8e     Abduction   \n",
       "21  209998281eac41cd3e3b55194219adaa     Abduction   \n",
       "22  bd8a142a8ae7d7250e4723f684d50b64     Abduction   \n",
       "23  bb0345399a3ea255e6d31f230e818d53     Abduction   \n",
       "24  c9249aa1fd1ac7dc1b7b71164a3de79d     Abduction   \n",
       "25  bb09ab0b5a7f2dd68c1057691287d985     Abduction   \n",
       "26  6ae1afd1662837a0294f1ac43b46c62c     Abduction   \n",
       "27  69da7307a5a7eb89d8c73a877841e42e     Abduction   \n",
       "28  603011c48c8bfc490ae806a1ba1b143c     Abduction   \n",
       "29  9f6b5d5c458131ee8547cc2b36012efd     Abduction   \n",
       "30  e429fb5c3e2a99a629105f9237b66a2d     Abduction   \n",
       "31  d9e78e99955c0b0ae1dc121c3099336d     Abduction   \n",
       "32  489106242e16717e1276835ca38b25f9     Abduction   \n",
       "33  025cb383324ec21cd8cb553cf1a8f8f9     Abduction   \n",
       "34  17ed98678b554b569ba01d9dce117a44     Abduction   \n",
       "35  944b677a84a379e8805518f72011e74c     Abduction   \n",
       "36  5238179758572338829937c7dda59f32     Abduction   \n",
       "37  d5e38b1922a893a6d1b887c9ea7a6c27     Abduction   \n",
       "38  5d84563da86fea01adfe1235cd360bdd     Abduction   \n",
       "39  337d80c564b6a3ca35e08b80301661b8     Abduction   \n",
       "40  2534a5a8ae83a361431b01c8e721d944     Abduction   \n",
       "\n",
       "                                         section_path    chunk_type  \\\n",
       "0                                                  []  full_article   \n",
       "1                    [1. Abduction: The General Idea]       section   \n",
       "2                    [1. Abduction: The General Idea]     paragraph   \n",
       "3                    [1. Abduction: The General Idea]     paragraph   \n",
       "4                    [1. Abduction: The General Idea]     paragraph   \n",
       "5                    [1. Abduction: The General Idea]     paragraph   \n",
       "6   [1. Abduction: The General Idea, 1.1 Deduction...    subsection   \n",
       "7   [1. Abduction: The General Idea, 1.2 The ubiqu...    subsection   \n",
       "8                          [2. Explicating Abduction]       section   \n",
       "9                          [2. Explicating Abduction]     paragraph   \n",
       "10                         [2. Explicating Abduction]     paragraph   \n",
       "11                         [2. Explicating Abduction]     paragraph   \n",
       "12                         [2. Explicating Abduction]     paragraph   \n",
       "13                         [2. Explicating Abduction]     paragraph   \n",
       "14                         [2. Explicating Abduction]     paragraph   \n",
       "15                         [2. Explicating Abduction]     paragraph   \n",
       "16                         [2. Explicating Abduction]     paragraph   \n",
       "17                         [2. Explicating Abduction]     paragraph   \n",
       "18                         [2. Explicating Abduction]     paragraph   \n",
       "19                         [2. Explicating Abduction]     paragraph   \n",
       "20                         [2. Explicating Abduction]     paragraph   \n",
       "21                         [2. Explicating Abduction]     paragraph   \n",
       "22                         [2. Explicating Abduction]     paragraph   \n",
       "23                         [2. Explicating Abduction]     paragraph   \n",
       "24                         [2. Explicating Abduction]     paragraph   \n",
       "25                       [3. The Status of Abduction]       section   \n",
       "26                       [3. The Status of Abduction]     paragraph   \n",
       "27       [3. The Status of Abduction, 3.1 Criticisms]    subsection   \n",
       "28         [3. The Status of Abduction, 3.2 Defenses]    subsection   \n",
       "29  [4. Abduction versus Bayesian Confirmation The...       section   \n",
       "30  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "31  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "32  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "33  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "34  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "35  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "36  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "37  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "38  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "39  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "40  [4. Abduction versus Bayesian Confirmation The...     paragraph   \n",
       "\n",
       "                                         philosophers  \\\n",
       "0                           [Charles Sanders\\nPeirce]   \n",
       "1   [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "2   [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "3   [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "4   [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "5   [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "6   [Louise, Tim, Harman, Harry’s, John, Bs, Harry...   \n",
       "7   [Josephson, Harman, Harry’s, Pargetter 1984, P...   \n",
       "8   [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "9   [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "10  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "11  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "12  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "13  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "14  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "15  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "16  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "17  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "18  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "19  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "20  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "21  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "22  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "23  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "24  [Douven, Koslowski, Williams, Patricia Mirabil...   \n",
       "25  [Koehler, Charles Sanders\\nPeirce, Brem, Lombr...   \n",
       "26  [Koehler, Charles Sanders\\nPeirce, Brem, Lombr...   \n",
       "27  [Koehler, van Fraassen’s, van Fraassen\\n1989, ...   \n",
       "28  [Koehler, Douven, Psillos, Lombrozo, Boyd 1981...   \n",
       "29  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "30  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "31  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "32  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "33  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "34  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "35  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "36  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "37  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "38  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "39  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "40  [Kosso, McGrew, Lewis, Weisberg, McCain, Jonat...   \n",
       "\n",
       "                                             concepts  \\\n",
       "0                                         [Inference]   \n",
       "1   [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "2   [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "3   [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "4   [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "5   [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "6   [Winston\\nChurchill, Hilary Putnam’s, Dutch, I...   \n",
       "7   [Dascal, Thomson, Stanford, Goldman, Winston\\n...   \n",
       "8   [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "9   [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "10  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "11  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "12  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "13  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "14  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "15  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "16  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "17  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "18  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "19  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "20  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "21  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "22  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "23  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "24  [Bayesian, ABD3, Lipton, Peirce, H1,, Igor Dou...   \n",
       "25                  [Lombrozo’s, Bayesian, Inference]   \n",
       "26                  [Lombrozo’s, Bayesian, Inference]   \n",
       "27  [Bayesian, Lorentz, Dutch, Bayes, Inference, L...   \n",
       "28  [Bayesian, See Harré, Inference, Lombrozo’s, N...   \n",
       "29  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "30  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "31  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "32  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "33  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "34  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "35  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "36  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "37  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "38  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "39  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "40  [Bayesian, Poston 2014, Lipton, Bayesians, Pei...   \n",
       "\n",
       "                                              content  \n",
       "0   \\nIn the philosophical literature, the term “a...  \n",
       "1   \\nYou happen to know that Tim and Harry have r...  \n",
       "2   \\nYou happen to know that Tim and Harry have r...  \n",
       "3   \\nOne morning you enter the kitchen to find a ...  \n",
       "4   \\nWalking along the beach, you see what looks ...  \n",
       "5   \\nIn these examples, the conclusions do not fo...  \n",
       "6   \\nAbduction is normally thought of as being on...  \n",
       "7   \\nThe type of inference exemplified in the cas...  \n",
       "8   \\nPrecise statements of what abduction amounts...  \n",
       "9   \\nPrecise statements of what abduction amounts...  \n",
       "10  \\nIn textbooks on epistemology or the philosop...  \n",
       "11  \\nAn observation that is frequently made about...  \n",
       "12  \\nFurthermore, many of those who think ABD1 is...  \n",
       "13  \\nThe real problem with ABD1 runs deeper than ...  \n",
       "14  \\nHow reasonable is it to suppose that this ex...  \n",
       "15  \\nIn response to this, one might argue that th...  \n",
       "16  \\nAlas, there is a catch. For even though ther...  \n",
       "17  \\nA more promising response to the above “argu...  \n",
       "18  \\nThe first option is to modify the rule so as...  \n",
       "19  \\nNeedless to say, ABD2 needs supplementing by...  \n",
       "20  \\nSecondly, one can formulate a symmetric or c...  \n",
       "21  \\nClearly, ABD3 requires an account of closene...  \n",
       "22  \\nOne noteworthy feature of the congruous vers...  \n",
       "23  \\nAs mentioned, there is widespread agreement ...  \n",
       "24  \\nWith respect to the normative question of wh...  \n",
       "25  \\nEven if it is true that we routinely rely on...  \n",
       "26  \\nEven if it is true that we routinely rely on...  \n",
       "27  \\nWe have already encountered the so-called ar...  \n",
       "28  \\nHardly anyone nowadays would want to subscri...  \n",
       "29  \\nIn the past decade, Bayesian confirmation th...  \n",
       "30  \\nIn the past decade, Bayesian confirmation th...  \n",
       "31  \\nThis requires some clarification. For what c...  \n",
       "32  \\nExactly how are explanatory considerations t...  \n",
       "33  \\nPerhaps Lipton’s proposal is not intended to...  \n",
       "34  \\n(As an aside, it should be noticed that, acc...  \n",
       "35  \\nA more interesting answer to the above quest...  \n",
       "36  \\nThe proposal is intriguing as far as it goes...  \n",
       "37  \\nAnother suggestion about the connection betw...  \n",
       "38  \\nBayesians, especially the more modest ones, ...  \n",
       "39  \\nPsillos (2000) proposes yet another way in w...  \n",
       "40  \\nFinally, a possibility that has so far not b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(chunks)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b2393e-2851-45bb-8ee0-5a101396ec81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>section_path</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>philosophers</th>\n",
       "      <th>concepts</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92dd2f6b5d033c12efb2f8ee3047601e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[]</td>\n",
       "      <td>full_article</td>\n",
       "      <td>[Charles Sanders\\nPeirce]</td>\n",
       "      <td>[Inference]</td>\n",
       "      <td>\\nIn the philosophical literature, the term “a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3b5103db83e97338eb7270a86a63c65</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>section</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>501b7b05cb58454829b17faa1ca0b67f</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nIn these examples, the conclusions do not fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           chunk_id article_title  \\\n",
       "0  92dd2f6b5d033c12efb2f8ee3047601e     Abduction   \n",
       "1  a3b5103db83e97338eb7270a86a63c65     Abduction   \n",
       "5  501b7b05cb58454829b17faa1ca0b67f     Abduction   \n",
       "\n",
       "                       section_path    chunk_type  \\\n",
       "0                                []  full_article   \n",
       "1  [1. Abduction: The General Idea]       section   \n",
       "5  [1. Abduction: The General Idea]     paragraph   \n",
       "\n",
       "                                        philosophers  \\\n",
       "0                          [Charles Sanders\\nPeirce]   \n",
       "1  [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "5  [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "\n",
       "                                            concepts  \\\n",
       "0                                        [Inference]   \n",
       "1  [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "5  [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "\n",
       "                                             content  \n",
       "0  \\nIn the philosophical literature, the term “a...  \n",
       "1  \\nYou happen to know that Tim and Harry have r...  \n",
       "5  \\nIn these examples, the conclusions do not fo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['content'].str.contains(\"What leads you to the conclusion\", case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b984ccb8-f055-48db-9392-2e1c6bce0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314cf25-6ab5-4372-8b33-32a42da94c47",
   "metadata": {},
   "source": [
    "\n",
    "for article in tqdm(dataset_subset, desc=\"Processing articles\"):\n",
    "     chunks = processor.process_article(article)\n",
    "     all_chunks.append(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d025aa-b3ee-4f10-b463-e2d3b8d90504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных из ../data/all_chunks_flatten.json...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "file_path = '../data/all_chunks_flatten.json'\n",
    "\n",
    "# Пытаемся загрузить данные из файла, если он существует\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Загрузка данных из {file_path}...\")\n",
    "    df = pd.read_json(file_path)\n",
    "    all_chunks = df.to_dict(orient='records')  # Преобразуем DataFrame обратно в список словарей\n",
    "else:\n",
    "    print(\"Файл не найден, выполнение обработки статей...\")\n",
    "    all_chunks = []  \n",
    "    for article in tqdm(dataset_subset, desc=\"Processing articles\"):\n",
    "        chunks = processor.process_article(article) \n",
    "        all_chunks.append(chunks)  \n",
    "    \n",
    "    def flatten_chain(matrix):\n",
    "        return list(chain.from_iterable(matrix))\n",
    "\n",
    "    flatten = flatten_chain(all_chunks)\n",
    "\n",
    "    # Преобразуем в DataFrame и сохраняем в JSON, если нужно\n",
    "    df = pd.DataFrame(flatten)\n",
    "    df.to_json(file_path, orient='records', indent=4, force_ascii=False)\n",
    "    print(f\"Обработанные данные сохранены в {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eeb6ab3-946a-4e20-956b-6e1f376e9eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>section_path</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>philosophers</th>\n",
       "      <th>concepts</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92dd2f6b5d033c12efb2f8ee3047601e</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[]</td>\n",
       "      <td>full_article</td>\n",
       "      <td>[Charles Sanders\\nPeirce]</td>\n",
       "      <td>[Inference]</td>\n",
       "      <td>\\nIn the philosophical literature, the term “a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a3b5103db83e97338eb7270a86a63c65</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>section</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81e573a9d329de10a9651c19c4907dc2</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           chunk_id article_title  \\\n",
       "0  92dd2f6b5d033c12efb2f8ee3047601e     Abduction   \n",
       "1  a3b5103db83e97338eb7270a86a63c65     Abduction   \n",
       "2  81e573a9d329de10a9651c19c4907dc2     Abduction   \n",
       "\n",
       "                       section_path    chunk_type  \\\n",
       "0                                []  full_article   \n",
       "1  [1. Abduction: The General Idea]       section   \n",
       "2  [1. Abduction: The General Idea]     paragraph   \n",
       "\n",
       "                                        philosophers  \\\n",
       "0                          [Charles Sanders\\nPeirce]   \n",
       "1  [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "2  [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "\n",
       "                                            concepts  \\\n",
       "0                                        [Inference]   \n",
       "1  [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "2  [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "\n",
       "                                             content  \n",
       "0  \\nIn the philosophical literature, the term “a...  \n",
       "1  \\nYou happen to know that Tim and Harry have r...  \n",
       "2  \\nYou happen to know that Tim and Harry have r...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_chunks)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0af76-45f3-4cb1-9f2b-33cb9c1870aa",
   "metadata": {},
   "source": [
    "## Create Embeddings using Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0aaf289-f9aa-4880-9e86-6a3f2cc0a349",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers) (2.4.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence_transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.38.0->sentence_transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.38.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading tokenizers-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed safetensors-0.4.5 sentence_transformers-3.1.1 tokenizers-0.20.0 transformers-4.45.1\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad98218-96e9-4618-9300-c9c9bebfd606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4683ce72-3d30-4805-9700-4bed6386f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d447d732-3226-4ce5-8d14-7d35566d6b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_doc(doc):\n",
    "    section_path = doc['section_path']\n",
    "    content = doc['content']\n",
    "    section_path = ' '.join(section_path)\n",
    "    content = ' '.join(content)\n",
    "    \n",
    "    doc['vector_sectionPath_content'] = model.encode(section_path + ' ' + content)\n",
    "    return doc\n",
    "\n",
    "def parallel_processing_doc(chunks_to_process):\n",
    "    # Parallel processing with ThreadPoolExecutor\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_doc, doc) for doc in chunks_to_process]\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            vectorized_articles.append(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1854ba86-5268-4184-aa09-aaca2c360b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note: I couldn't wait, so I only processed some of the elements. You can do it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ac8063-ec8a-45d8-9747-fb8a3a8ad341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████▏                                   | 7237/14578 [48:31<49:13,  2.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m, in \u001b[0;36mparallel_processing_doc\u001b[0;34m(chunks_to_process)\u001b[0m\n\u001b[1;32m     16\u001b[0m futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(process_doc, doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunks_to_process]\n\u001b[0;32m---> 18\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorized_articles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chunks_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m chunks_to \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_chunks)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mparallel_processing_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_chunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunks_from\u001b[49m\u001b[43m:\u001b[49m\u001b[43mchunks_to\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mparallel_processing_doc\u001b[0;34m(chunks_to_process)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_processing_doc\u001b[39m(chunks_to_process):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Parallel processing with ThreadPoolExecutor\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks_to_process\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/concurrent/futures/thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 238\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunks_from = 7237\n",
    "chunks_to = len(all_chunks)\n",
    "parallel_processing_doc(all_chunks[chunks_from:chunks_to])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8ddea3e-5506-495a-a6be-04b73cbe9d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7237"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76e0584a-3208-4fd7-bbe0-c69b50f2b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>section_path</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>philosophers</th>\n",
       "      <th>concepts</th>\n",
       "      <th>content</th>\n",
       "      <th>vector_sectionPath_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81e573a9d329de10a9651c19c4907dc2</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nYou happen to know that Tim and Harry have r...</td>\n",
       "      <td>[0.04034751, -0.010665092, 0.017695744, -0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1738ba0482fa09f893136ec9e10ebff5</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nOne morning you enter the kitchen to find a ...</td>\n",
       "      <td>[0.039968688, -0.035628095, 0.010803069, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>806563744b1ad2c6fdc20c84694a9061</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea, 1.2 The ubiqu...</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Josephson, Harman, Harry’s, Pargetter 1984, P...</td>\n",
       "      <td>[Dascal, Thomson, Stanford, Goldman, Winston\\n...</td>\n",
       "      <td>\\nThe type of inference exemplified in the cas...</td>\n",
       "      <td>[0.049834765, -0.0046678144, 0.013743385, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34bf01c649b729cd3d740f4d5a7cdadf</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...</td>\n",
       "      <td>[the Best\\nExplanation, Hilary Putnam’s, Infer...</td>\n",
       "      <td>\\nWalking along the beach, you see what looks ...</td>\n",
       "      <td>[0.03520298, -0.013972833, 0.021752857, 0.0023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6c943762de83a112fe91d3de929913e8</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[1. Abduction: The General Idea, 1.1 Deduction...</td>\n",
       "      <td>subsection</td>\n",
       "      <td>[Louise, Tim, Harman, Harry’s, John, Bs, Harry...</td>\n",
       "      <td>[Winston\\nChurchill, Hilary Putnam’s, Dutch, I...</td>\n",
       "      <td>\\nAbduction is normally thought of as being on...</td>\n",
       "      <td>[0.021810336, 0.0011034051, 0.017931415, 0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7232</th>\n",
       "      <td>02cd9ef520b1d9b6c9bc1c278c858364</td>\n",
       "      <td>Francis Herbert Bradley</td>\n",
       "      <td>[5. Logic]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...</td>\n",
       "      <td>[Hegelian, British, Humean, British Idealists,...</td>\n",
       "      <td>\\nThis may be called the law of Redintegration...</td>\n",
       "      <td>[-0.040556494, 0.010700114, -0.008341639, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233</th>\n",
       "      <td>ec45ed3889690568cd9029036fda09f3</td>\n",
       "      <td>Francis Herbert Bradley</td>\n",
       "      <td>[5. Logic]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...</td>\n",
       "      <td>[Hegelian, British, Humean, British Idealists,...</td>\n",
       "      <td>\\nBradley’s own account of judgment is that it...</td>\n",
       "      <td>[0.006766742, 0.026081122, 0.020721044, 0.0448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>679a9a016377af62b58a9b542e3ab962</td>\n",
       "      <td>Francis Herbert Bradley</td>\n",
       "      <td>[5. Logic]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...</td>\n",
       "      <td>[Hegelian, British, Humean, British Idealists,...</td>\n",
       "      <td>\\nBradley continues to criticize traditional l...</td>\n",
       "      <td>[-0.0149703985, 0.0056009805, -0.0011972125, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>2d50d20ecdf273ef8eb0de14d0af5463</td>\n",
       "      <td>Francis Herbert Bradley</td>\n",
       "      <td>[5. Logic]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...</td>\n",
       "      <td>[Hegelian, British, Humean, British Idealists,...</td>\n",
       "      <td>\\nDespite these significant steps in the direc...</td>\n",
       "      <td>[-0.012884118, 0.020164268, -0.001750762, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>846c6d53458decc1c64ed63268ec90fe</td>\n",
       "      <td>Francis Herbert Bradley</td>\n",
       "      <td>[5. Logic]</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>[Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...</td>\n",
       "      <td>[Hegelian, British, Humean, British Idealists,...</td>\n",
       "      <td>\\nSurprisingly for those who subscribe to the ...</td>\n",
       "      <td>[-0.024804717, 0.00092663313, 0.0031016269, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7237 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chunk_id            article_title  \\\n",
       "0     81e573a9d329de10a9651c19c4907dc2                Abduction   \n",
       "1     1738ba0482fa09f893136ec9e10ebff5                Abduction   \n",
       "2     806563744b1ad2c6fdc20c84694a9061                Abduction   \n",
       "3     34bf01c649b729cd3d740f4d5a7cdadf                Abduction   \n",
       "4     6c943762de83a112fe91d3de929913e8                Abduction   \n",
       "...                                ...                      ...   \n",
       "7232  02cd9ef520b1d9b6c9bc1c278c858364  Francis Herbert Bradley   \n",
       "7233  ec45ed3889690568cd9029036fda09f3  Francis Herbert Bradley   \n",
       "7234  679a9a016377af62b58a9b542e3ab962  Francis Herbert Bradley   \n",
       "7235  2d50d20ecdf273ef8eb0de14d0af5463  Francis Herbert Bradley   \n",
       "7236  846c6d53458decc1c64ed63268ec90fe  Francis Herbert Bradley   \n",
       "\n",
       "                                           section_path  chunk_type  \\\n",
       "0                      [1. Abduction: The General Idea]   paragraph   \n",
       "1                      [1. Abduction: The General Idea]   paragraph   \n",
       "2     [1. Abduction: The General Idea, 1.2 The ubiqu...  subsection   \n",
       "3                      [1. Abduction: The General Idea]   paragraph   \n",
       "4     [1. Abduction: The General Idea, 1.1 Deduction...  subsection   \n",
       "...                                                 ...         ...   \n",
       "7232                                         [5. Logic]   paragraph   \n",
       "7233                                         [5. Logic]   paragraph   \n",
       "7234                                         [5. Logic]   paragraph   \n",
       "7235                                         [5. Logic]   paragraph   \n",
       "7236                                         [5. Logic]   paragraph   \n",
       "\n",
       "                                           philosophers  \\\n",
       "0     [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "1     [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "2     [Josephson, Harman, Harry’s, Pargetter 1984, P...   \n",
       "3     [Tim, Harry’s, Harry, Charles Sanders\\nPeirce,...   \n",
       "4     [Louise, Tim, Harman, Harry’s, John, Bs, Harry...   \n",
       "...                                                 ...   \n",
       "7232  [Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...   \n",
       "7233  [Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...   \n",
       "7234  [Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...   \n",
       "7235  [Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...   \n",
       "7236  [Hermann Lotze, Hegel, Bertrand\\nRussell, McTa...   \n",
       "\n",
       "                                               concepts  \\\n",
       "0     [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "1     [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "2     [Dascal, Thomson, Stanford, Goldman, Winston\\n...   \n",
       "3     [the Best\\nExplanation, Hilary Putnam’s, Infer...   \n",
       "4     [Winston\\nChurchill, Hilary Putnam’s, Dutch, I...   \n",
       "...                                                 ...   \n",
       "7232  [Hegelian, British, Humean, British Idealists,...   \n",
       "7233  [Hegelian, British, Humean, British Idealists,...   \n",
       "7234  [Hegelian, British, Humean, British Idealists,...   \n",
       "7235  [Hegelian, British, Humean, British Idealists,...   \n",
       "7236  [Hegelian, British, Humean, British Idealists,...   \n",
       "\n",
       "                                                content  \\\n",
       "0     \\nYou happen to know that Tim and Harry have r...   \n",
       "1     \\nOne morning you enter the kitchen to find a ...   \n",
       "2     \\nThe type of inference exemplified in the cas...   \n",
       "3     \\nWalking along the beach, you see what looks ...   \n",
       "4     \\nAbduction is normally thought of as being on...   \n",
       "...                                                 ...   \n",
       "7232  \\nThis may be called the law of Redintegration...   \n",
       "7233  \\nBradley’s own account of judgment is that it...   \n",
       "7234  \\nBradley continues to criticize traditional l...   \n",
       "7235  \\nDespite these significant steps in the direc...   \n",
       "7236  \\nSurprisingly for those who subscribe to the ...   \n",
       "\n",
       "                             vector_sectionPath_content  \n",
       "0     [0.04034751, -0.010665092, 0.017695744, -0.001...  \n",
       "1     [0.039968688, -0.035628095, 0.010803069, -0.00...  \n",
       "2     [0.049834765, -0.0046678144, 0.013743385, -0.0...  \n",
       "3     [0.03520298, -0.013972833, 0.021752857, 0.0023...  \n",
       "4     [0.021810336, 0.0011034051, 0.017931415, 0.011...  \n",
       "...                                                 ...  \n",
       "7232  [-0.040556494, 0.010700114, -0.008341639, 0.01...  \n",
       "7233  [0.006766742, 0.026081122, 0.020721044, 0.0448...  \n",
       "7234  [-0.0149703985, 0.0056009805, -0.0011972125, 0...  \n",
       "7235  [-0.012884118, 0.020164268, -0.001750762, 0.01...  \n",
       "7236  [-0.024804717, 0.00092663313, 0.0031016269, 0....  \n",
       "\n",
       "[7237 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vectorized_articles)\n",
    "df.to_json('../data/vectorized_articles.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426516a8-c50c-4112-9303-16ff5d54a5e4",
   "metadata": {},
   "source": [
    "## ElasticSearch Ingestion (with Vector Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804ade0-c9c3-4023-ba0b-e8152cff03e9",
   "metadata": {},
   "source": [
    "Running ElasticSearch locally (you don't need it, if you use my hosted elastic):\n",
    "```\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483fa02e-0694-4ba3-9f33-12dbd0543c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f519cd-3b0f-4690-b2da-d264f8de9eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None:None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "load_dotenv()\n",
    "print(f\"{os.getenv('ELASTIC_HOST')}:{os.getenv('ELASTIC_PORT')}\")\n",
    "\n",
    "#es_client = Elasticsearch(f\"{os.getenv('ELASTIC_HOST')}:{os.getenv('ELASTIC_PORT')}\", api_key=os.getenv('ELASTIC_API_KEY'))\n",
    "#es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4c773-0454-42a7-a536-28b6a987d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Путь к файлу JSON\n",
    "file_path = '../data/vectorized_articles.json'\n",
    "\n",
    "# Пытаемся загрузить данные из файла, если он существует\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Загрузка данных из {file_path}...\")\n",
    "    df = pd.read_json(file_path)  # Загружаем JSON в DataFrame\n",
    "    to_index_vectorized_articles = df.to_dict(orient='records')  # Преобразуем DataFrame в список словарей\n",
    "else:\n",
    "    print(\"Файл не найден, создайте или загрузите данные для индексации.\")\n",
    "    to_index_vectorized_articles = []  # Пустой список или замена на ваш процесс получения данных\n",
    "\n",
    "# Проверяем, есть ли данные для индексации\n",
    "if to_index_vectorized_articles:\n",
    "    # Выполняем индексацию в Elasticsearch\n",
    "    index_articles(es_client, index_name, to_index_vectorized_articles)\n",
    "    print(\"Индексация завершена.\")\n",
    "else:\n",
    "    print(\"Нет данных для индексации.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20366fd8-56a9-44e5-a58f-c619fb3d2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class ElasticIngestion:\n",
    "    def __init__(self, es_client): \n",
    "        self.index_name = \"philosophy\"\n",
    "        self.setup_elasticsearch()\n",
    "\n",
    "    def setup_elasticsearch(self):\n",
    "        # Define the index mapping\n",
    "        index_settings = {\n",
    "            \"settings\": {\n",
    "                \"number_of_shards\": 1,\n",
    "                \"number_of_replicas\": 0\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"chunk_id\": {\"type\": \"keyword\"},\n",
    "                    \"article_title\": {\"type\": \"text\"},\n",
    "                    \"section_path\": {\"type\": \"keyword\"},\n",
    "                    \"chunk_type\": {\"type\": \"keyword\"},\n",
    "                    \"philosophers\": {\"type\": \"keyword\"},\n",
    "                    \"concepts\": {\"type\": \"keyword\"},\n",
    "                    \"content\": {\"type\": \"text\"},\n",
    "                    \"vector_sectionPath_content\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 768, # for all-mpnet-base-v2 model,\n",
    "                        \"index\": True, \n",
    "                        \"similarity\": \"cosine\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        # Create the index if it doesn't exist\n",
    "        if not es_client.indices.exists(index=self.index_name):\n",
    "            es_client.indices.create(index=self.index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9201ee-6d53-413c-a0b6-d34f207ceb5e",
   "metadata": {},
   "source": [
    "### Add chunks to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fa7090f-ce6c-47af-9a61-4fe9245df5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing articles: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7237/7237 [01:23<00:00, 86.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "\n",
    "def index_articles(es_client, index_name, vectorized_articles):\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": chunk['chunk_id'],\n",
    "            \"_source\": chunk\n",
    "        }\n",
    "        for chunk in vectorized_articles\n",
    "    ]\n",
    "    \n",
    "    for ok, response in tqdm(helpers.streaming_bulk(es_client, actions), total=len(actions), desc=\"Indexing articles\"):\n",
    "        if not ok:\n",
    "            print(f\"Failed to index document: {response}\")\n",
    "\n",
    "index_name = 'philosophy'\n",
    "\n",
    "# Ingest vectorized articles with tqdm progress tracking\n",
    "index_articles(es_client, index_name, vectorized_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10dd3920-3302-4fe2-af9e-8fd25ddec430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document in Elasticsearch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"chunk_id\": \"81e573a9d329de10a9651c19c4907dc2\",\\n  \"article_title\": \"Abduction\",\\n  \"section_path\": [\\n    \"1. Abduction: The General Idea\"\\n  ],\\n  \"chunk_type\": \"paragraph\",\\n  \"philosophers\": [\\n    \"Tim\",\\n    \"Harry\\\\u2019s\",\\n    \"Harry\",\\n    \"Charles Sanders\\\\nPeirce\",\\n    \"Churchill\"\\n  ],\\n  \"concepts\": [\\n    \"the Best\\\\nExplanation\",\\n    \"Hilary Putnam\\\\u2019s\",\\n    \"Inference\",\\n    \"Winston\\\\nChurchill\"\\n  ],\\n  \"content\": \"\\\\nYou happen to know that Tim and Harry have recently had a terrible row\\\\nthat ended their friendship. Now someone tells you that she just saw\\\\nTim and Harry jogging together. The best explanation for this that you\\\\ncan think of is that they made up. You conclude that they are friends\\\\nagain.\",\\n  \"vector_sectionPath_content\": [\\n    0.04034750908613205,\\n    -0.010665091685950756,\\n    0.017695743590593338,\\n    -0.0017783143557608128,\\n    -0.054355766624212265,\\n    -0.006915545556694269,\\n    0.01386959757655859,\\n    -0.018539706245064735,\\n    -0.01344980113208294,\\n    -0.01052915956825018,\\n    -0.00948254019021988,\\n    -0.04451565071940422,\\n    0.0165280532091856,\\n    -0.020980799570679665,\\n    -0.01124432124197483,\\n    -0.09510213881731033,\\n    0.013204934075474739,\\n    0.011362780816853046,\\n    0.003969775978475809,\\n    0.008034742437303066,\\n    -0.001090566860511899,\\n    0.011417190544307232,\\n    -0.031996604055166245,\\n    -0.003025823039934039,\\n    0.005172438453882933,\\n    -0.03207537159323692,\\n    -0.08542393147945404,\\n    0.005032432731240988,\\n    -0.03445179760456085,\\n    -0.025788018479943275,\\n    0.019835276529192924,\\n    0.03605563938617706,\\n    -0.00498062651604414,\\n    0.014858311973512173,\\n    2.5913745957950596e-06,\\n    -0.026071907952427864,\\n    -0.03430436924099922,\\n    -0.023055942729115486,\\n    0.04364800825715065,\\n    0.0219408106058836,\\n    -0.014400924555957317,\\n    -0.010245760902762413,\\n    0.019181881099939346,\\n    -0.04501533508300781,\\n    -0.010596614331007004,\\n    0.01685134880244732,\\n    0.017234647646546364,\\n    0.03373817354440689,\\n    0.055869948118925095,\\n    -0.014517107978463173,\\n    -0.006484934128820896,\\n    0.03782333806157112,\\n    -0.032007887959480286,\\n    -0.009266792796552181,\\n    0.09862929582595825,\\n    -3.6871810152661055e-05,\\n    -0.022483283653855324,\\n    0.01157439686357975,\\n    0.08170510083436966,\\n    0.005492245312780142,\\n    0.032312825322151184,\\n    -0.006342984735965729,\\n    -0.03005240671336651,\\n    -0.04946241155266762,\\n    0.021233126521110535,\\n    -0.0264308899641037,\\n    -0.05612536519765854,\\n    -0.08128932118415833,\\n    -0.009458454325795174,\\n    -0.01663624495267868,\\n    0.015316939912736416,\\n    0.0010052630677819252,\\n    -0.004125296603888273,\\n    0.10203833878040314,\\n    -0.010634761303663254,\\n    -0.02504529245197773,\\n    -0.04721784591674805,\\n    0.03929255157709122,\\n    0.015129667706787586,\\n    0.0232330784201622,\\n    0.09187296777963638,\\n    0.05906819552183151,\\n    -0.02280195616185665,\\n    0.026947977021336555,\\n    -0.0032902853563427925,\\n    0.03272515907883644,\\n    0.026949862018227577,\\n    -0.04397834837436676,\\n    -0.011407813988626003,\\n    -0.03230360150337219,\\n    -0.07472501695156097,\\n    -0.04360724985599518,\\n    0.06754260510206223,\\n    0.029575368389487267,\\n    -0.0022954659070819616,\\n    -0.025441210716962814,\\n    0.0003802773717325181,\\n    -0.06447708606719971,\\n    -0.02170284278690815,\\n    -0.11132408678531647,\\n    -0.03157452121376991,\\n    0.007759374100714922,\\n    0.012570999562740326,\\n    0.022308431565761566,\\n    0.0031751831993460655,\\n    0.025295613333582878,\\n    -0.042061761021614075,\\n    0.04823404550552368,\\n    -0.011489096097648144,\\n    0.07993307709693909,\\n    -0.0644647553563118,\\n    -0.0006161818164400756,\\n    -0.06478975713253021,\\n    0.03141028434038162,\\n    -0.015303133055567741,\\n    -0.003861366305500269,\\n    0.03206987679004669,\\n    -0.015264815650880337,\\n    0.00823358353227377,\\n    0.012798629701137543,\\n    -0.10882464051246643,\\n    0.028556881472468376,\\n    -0.05233437195420265,\\n    0.0036374307237565517,\\n    0.021161355078220367,\\n    0.002123186830431223,\\n    -0.08009828627109528,\\n    0.008197576738893986,\\n    0.008459306322038174,\\n    -0.024493303149938583,\\n    -0.053395237773656845,\\n    -0.011292868293821812,\\n    0.012748600915074348,\\n    0.006306075025349855,\\n    -0.004839603789150715,\\n    0.024622343480587006,\\n    -0.016197485849261284,\\n    0.010664055123925209,\\n    -0.05456768721342087,\\n    -0.03316487744450569,\\n    0.00616660388186574,\\n    -0.003170292591676116,\\n    -0.027865268290042877,\\n    -0.00514775887131691,\\n    -0.016334103420376778,\\n    -0.03027542680501938,\\n    0.00917904730886221,\\n    -0.05760045349597931,\\n    0.04054906591773033,\\n    -0.01924608275294304,\\n    -0.029532302170991898,\\n    0.01965375803411007,\\n    0.04898758977651596,\\n    0.010285659693181515,\\n    0.037888843566179276,\\n    0.046747468411922455,\\n    0.007056702394038439,\\n    0.023342132568359375,\\n    0.029496217146515846,\\n    0.07424267381429672,\\n    0.05888825282454491,\\n    0.012784904800355434,\\n    0.07476107776165009,\\n    0.01200412679463625,\\n    -0.022017179057002068,\\n    0.014626024290919304,\\n    0.11247286200523376,\\n    -0.04761671647429466,\\n    0.018125168979167938,\\n    0.009221062995493412,\\n    -0.0312918983399868,\\n    -0.00528913177549839,\\n    0.01121146697551012,\\n    0.059518054127693176,\\n    0.0005659332382492721,\\n    0.1275523453950882,\\n    -0.042508721351623535,\\n    0.015253528952598572,\\n    -0.0625544860959053,\\n    -0.02024657651782036,\\n    -0.05012720078229904,\\n    0.02536187879741192,\\n    -0.020305436104536057,\\n    0.016825592145323753,\\n    0.033289048820734024,\\n    -0.03303516283631325,\\n    -0.04247884824872017,\\n    0.04170297458767891,\\n    -0.03023543208837509,\\n    -0.0067027248442173,\\n    -0.008028581738471985,\\n    0.04557681828737259,\\n    -0.022916922345757484,\\n    0.011471245437860489,\\n    0.010124914348125458,\\n    0.02607966773211956,\\n    0.030168237164616585,\\n    0.03361443057656288,\\n    0.009312327019870281,\\n    -0.011244472116231918,\\n    -0.009401122108101845,\\n    0.031082255765795708,\\n    0.04076001048088074,\\n    -0.030523309484124184,\\n    -0.018916144967079163,\\n    0.019252432510256767,\\n    -0.009487967938184738,\\n    -0.013970458880066872,\\n    0.019727393984794617,\\n    0.022902656346559525,\\n    -0.07528740912675858,\\n    0.012226201593875885,\\n    -0.0066986377350986,\\n    0.041460659354925156,\\n    -0.01366438902914524,\\n    0.057068414986133575,\\n    0.01628427952528,\\n    -0.007050409447401762,\\n    -0.04783082380890846,\\n    0.009002074599266052,\\n    0.020834608003497124,\\n    0.04351940378546715,\\n    -0.0073540592566132545,\\n    0.022362880408763885,\\n    0.0013976892223581672,\\n    -0.062061503529548645,\\n    -0.04280880466103554,\\n    0.03717817738652229,\\n    0.04698839783668518,\\n    0.024011265486478806,\\n    0.03041718155145645,\\n    0.025583507493138313,\\n    0.012171315029263496,\\n    0.005270695313811302,\\n    0.0006023060414008796,\\n    0.0370381698012352,\\n    0.041602812707424164,\\n    0.06961756199598312,\\n    -0.022094987332820892,\\n    -0.0875711441040039,\\n    0.01896318979561329,\\n    -0.05152798071503639,\\n    -0.005656968802213669,\\n    0.002634201431646943,\\n    0.07596761733293533,\\n    0.012600697576999664,\\n    0.01650064066052437,\\n    -0.004648829344660044,\\n    -0.028365671634674072,\\n    -0.0015577118610963225,\\n    -0.013249923475086689,\\n    -0.016185151413083076,\\n    -0.027952097356319427,\\n    -0.008847019635140896,\\n    -0.003317339811474085,\\n    -0.0756719708442688,\\n    -0.04538135975599289,\\n    0.02685002237558365,\\n    0.02247506007552147,\\n    0.013973362743854523,\\n    -0.0033795943018049,\\n    -0.001985733164474368,\\n    0.04367461055517197,\\n    0.005098068621009588,\\n    0.01503452006727457,\\n    -0.03797036409378052,\\n    -0.020485492423176765,\\n    0.039090581238269806,\\n    -0.004813686478883028,\\n    -0.008180131204426289,\\n    0.03524446859955788,\\n    0.030255170539021492,\\n    0.052637770771980286,\\n    -0.036024898290634155,\\n    0.016825305297970772,\\n    0.010605371557176113,\\n    -0.040119290351867676,\\n    -0.00458551524206996,\\n    0.03392849490046501,\\n    -0.043416496366262436,\\n    0.03821324557065964,\\n    0.00918892864137888,\\n    -0.011331410147249699,\\n    0.010557693429291248,\\n    0.01753191649913788,\\n    0.02280241996049881,\\n    -0.04067313298583031,\\n    0.007455282844603062,\\n    0.02926378697156906,\\n    -0.029305288568139076,\\n    -0.012847480364143848,\\n    -0.0014507034793496132,\\n    0.007415380794554949,\\n    -0.04193916544318199,\\n    0.031017662957310677,\\n    -0.062242574989795685,\\n    -0.04458418861031532,\\n    0.06404809653759003,\\n    -0.03880049288272858,\\n    0.021657366305589676,\\n    0.005311315413564444,\\n    -0.012322877533733845,\\n    -0.0026720797177404165,\\n    -0.001666886848397553,\\n    -0.016917310655117035,\\n    -0.005616833455860615,\\n    0.058787520974874496,\\n    -0.044011689722537994,\\n    -0.02077494189143181,\\n    0.0373496375977993,\\n    0.04293908178806305,\\n    0.003254747251048684,\\n    0.0053198873065412045,\\n    -0.06782785803079605,\\n    -0.029408402740955353,\\n    -0.016757074743509293,\\n    -0.037355609238147736,\\n    -0.04696803539991379,\\n    -0.020990921184420586,\\n    0.07749756425619125,\\n    -0.06264947354793549,\\n    -0.01025819405913353,\\n    -0.040046244859695435,\\n    0.03169481083750725,\\n    -0.04226010665297508,\\n    0.01729251816868782,\\n    0.01794956624507904,\\n    0.016894280910491943,\\n    0.0787777453660965,\\n    -0.02552977204322815,\\n    0.03489166125655174,\\n    0.0014867548597976565,\\n    -0.018849046900868416,\\n    0.0218562763184309,\\n    0.004631954710930586,\\n    0.00904614757746458,\\n    -0.04585171118378639,\\n    0.004463894292712212,\\n    -0.023842543363571167,\\n    -0.03191955387592316,\\n    0.013390663079917431,\\n    -0.026284746825695038,\\n    -0.0502784363925457,\\n    0.025923077017068863,\\n    -0.0019867513328790665,\\n    -0.05573134496808052,\\n    -0.07492862641811371,\\n    0.00973785761743784,\\n    0.022411981597542763,\\n    -0.005034762434661388,\\n    0.018539324402809143,\\n    -7.669259503018111e-05,\\n    0.009084354154765606,\\n    0.005666736513376236,\\n    -0.011409701779484749,\\n    0.007509769406169653,\\n    -0.04358094558119774,\\n    -0.01341225579380989,\\n    -0.05099138617515564,\\n    -0.04117473587393761,\\n    -0.04539843276143074,\\n    0.050655148923397064,\\n    -0.017965558916330338,\\n    -0.013082250952720642,\\n    0.027973413467407227,\\n    0.05347197875380516,\\n    0.024150989949703217,\\n    -0.00711422972381115,\\n    -0.021031787618994713,\\n    -0.03817133978009224,\\n    -0.018360106274485588,\\n    0.014982958324253559,\\n    -0.0352567620575428,\\n    0.027998697012662888,\\n    0.012564562261104584,\\n    -0.024607736617326736,\\n    0.017613526433706284,\\n    -0.037772297859191895,\\n    0.059822749346494675,\\n    -0.009478147141635418,\\n    0.0024857420939952135,\\n    -0.03187296912074089,\\n    0.08106338977813721,\\n    0.009156690910458565,\\n    0.026238536462187767,\\n    0.018869096413254738,\\n    -0.0021365792490541935,\\n    0.001371601247228682,\\n    0.0013844132190570235,\\n    -0.017442772164940834,\\n    0.042109400033950806,\\n    -0.013243189081549644,\\n    -0.043691668659448624,\\n    -0.044978320598602295,\\n    0.026361316442489624,\\n    0.011912367306649685,\\n    -0.05795416980981827,\\n    0.015702538192272186,\\n    0.011685505509376526,\\n    0.06639444082975388,\\n    0.003562769154086709,\\n    0.021784653887152672,\\n    0.07636695355176926,\\n    0.022325647994875908,\\n    -0.041267458349466324,\\n    -0.09828253090381622,\\n    0.041980840265750885,\\n    0.017938362434506416,\\n    -0.020432863384485245,\\n    -0.001602567033842206,\\n    -0.0321003757417202,\\n    0.012118884362280369,\\n    -0.06925985217094421,\\n    0.009632916189730167,\\n    -0.012588267214596272,\\n    -0.011157949455082417,\\n    0.006797124166041613,\\n    -0.07232674211263657,\\n    0.03701889142394066,\\n    -0.03419321030378342,\\n    -0.034449297934770584,\\n    0.029300549998879433,\\n    0.034637343138456345,\\n    0.0011208723299205303,\\n    -0.022950567305088043,\\n    0.008846092969179153,\\n    0.012207399122416973,\\n    0.030359545722603798,\\n    -0.008787941187620163,\\n    0.00353301246650517,\\n    0.008002144284546375,\\n    0.004256724379956722,\\n    -0.03119082748889923,\\n    0.02426242083311081,\\n    -0.057950619608163834,\\n    -0.027207471430301666,\\n    0.0492778979241848,\\n    -0.01770053058862686,\\n    5.2685049013234675e-05,\\n    -0.060149818658828735,\\n    0.0317513607442379,\\n    0.03481225296854973,\\n    0.1282178908586502,\\n    0.050467707216739655,\\n    -0.00770511943846941,\\n    -0.0019313297234475613,\\n    -0.033322788774967194,\\n    -0.014896360225975513,\\n    0.05065109208226204,\\n    0.03867808356881142,\\n    -0.034689802676439285,\\n    0.06389588117599487,\\n    0.008114178664982319,\\n    -0.06897634267807007,\\n    0.044765789061784744,\\n    -0.013085895217955112,\\n    -0.054697513580322266,\\n    0.018637269735336304,\\n    -0.005202386528253555,\\n    0.06082889065146446,\\n    0.03547469154000282,\\n    0.04899328947067261,\\n    -0.031004300341010094,\\n    -0.040812037885189056,\\n    0.039109840989112854,\\n    -0.007836182601749897,\\n    -0.07366582751274109,\\n    0.006882333662360907,\\n    0.013953924179077148,\\n    -0.031679991632699966,\\n    -0.03365621343255043,\\n    0.003962677903473377,\\n    -0.02588162012398243,\\n    -0.021785948425531387,\\n    -0.007817179895937443,\\n    -0.011304528452455997,\\n    -0.06103747710585594,\\n    -0.051520295441150665,\\n    -0.028013763949275017,\\n    0.028909949585795403,\\n    0.01490013673901558,\\n    0.07857894897460938,\\n    -0.03294814005494118,\\n    0.002121998928487301,\\n    0.013415548950433731,\\n    -0.04018239676952362,\\n    0.04513033106923103,\\n    -0.03189241886138916,\\n    -0.004568885080516338,\\n    -0.010398129001259804,\\n    0.001541406149044633,\\n    0.01450149342417717,\\n    -0.006472633220255375,\\n    0.0255749449133873,\\n    0.04384925961494446,\\n    0.007361035328358412,\\n    -0.024999286979436874,\\n    0.03775078430771828,\\n    0.02366056852042675,\\n    0.03198928385972977,\\n    0.022844115272164345,\\n    0.03072531707584858,\\n    -0.002471559215337038,\\n    0.03154334798455238,\\n    -0.02904568240046501,\\n    0.07299776375293732,\\n    -0.044435739517211914,\\n    0.0039214929565787315,\\n    0.020517386496067047,\\n    0.008548811078071594,\\n    -0.03140641376376152,\\n    0.02321508340537548,\\n    -0.02567785233259201,\\n    -0.097869873046875,\\n    0.0013717708643525839,\\n    -0.018174614757299423,\\n    -0.003275482449680567,\\n    -0.05926378071308136,\\n    0.01535191759467125,\\n    0.0017691957764327526,\\n    -0.00470662722364068,\\n    -0.002126216422766447,\\n    0.020276319235563278,\\n    -0.003472732612863183,\\n    -0.04181604087352753,\\n    0.012225225567817688,\\n    0.023209717124700546,\\n    0.053688690066337585,\\n    0.021229736506938934,\\n    -0.005464655812829733,\\n    -0.08530325442552567,\\n    0.025701947510242462,\\n    0.0506436824798584,\\n    0.021137788891792297,\\n    -0.00867473240941763,\\n    0.04246268793940544,\\n    -0.019267410039901733,\\n    -0.01825522445142269,\\n    0.027065692469477654,\\n    -0.026443637907505035,\\n    -0.053974900394678116,\\n    -0.035455673933029175,\\n    -0.0178093109279871,\\n    0.009581075981259346,\\n    0.007582023739814758,\\n    0.030926421284675598,\\n    0.02748694270849228,\\n    -0.0220253374427557,\\n    0.0129628237336874,\\n    -0.04563469812273979,\\n    0.007274948060512543,\\n    -0.0037302961573004723,\\n    -0.00021716834453400224,\\n    -0.0436689630150795,\\n    0.049299921840429306,\\n    -6.923428831525017e-33,\\n    -0.021035097539424896,\\n    -0.006958215031772852,\\n    -0.012804861180484295,\\n    0.06332214921712875,\\n    -0.0837174654006958,\\n    -0.06403622776269913,\\n    -0.031214339658617973,\\n    0.02994598262012005,\\n    -0.03003630042076111,\\n    -0.009456387721002102,\\n    0.007438518572598696,\\n    -0.0028021973557770252,\\n    0.015705883502960205,\\n    -0.008739961311221123,\\n    0.027811476960778236,\\n    0.026824304834008217,\\n    -0.02680111490190029,\\n    0.012651711702346802,\\n    -0.0310987401753664,\\n    -0.05781581252813339,\\n    0.034358780831098557,\\n    0.020252766087651253,\\n    0.061985790729522705,\\n    0.04989347606897354,\\n    0.0375632606446743,\\n    -0.07006125897169113,\\n    -0.06550391018390656,\\n    0.0025530951097607613,\\n    -0.018633581697940826,\\n    -0.030319295823574066,\\n    -0.029947912320494652,\\n    -0.04886513948440552,\\n    9.912193490890786e-05,\\n    0.01009205263108015,\\n    0.028947262093424797,\\n    0.09979335218667984,\\n    -0.03363281115889549,\\n    0.0057275500148534775,\\n    -0.008435819298028946,\\n    0.004011775366961956,\\n    -0.05358857288956642,\\n    -0.043814461678266525,\\n    -0.059941574931144714,\\n    -0.005455899517983198,\\n    0.03223128989338875,\\n    -0.05632556974887848,\\n    -0.018896279856562614,\\n    0.0034557266626507044,\\n    -0.029594661667943,\\n    0.0986030250787735,\\n    -0.0272443275898695,\\n    -0.03797883912920952,\\n    -0.01643805205821991,\\n    -0.03272675722837448,\\n    0.04985234886407852,\\n    -0.021476687863469124,\\n    -0.02210772968828678,\\n    -0.0389222577214241,\\n    0.07873959094285965,\\n    0.00023192744993139058,\\n    -0.027202172204852104,\\n    0.014619828201830387,\\n    -0.05318457633256912,\\n    0.02571498602628708,\\n    -0.013403014279901981,\\n    0.0028938469476997852,\\n    -0.016691779717803,\\n    -0.04354795441031456,\\n    -0.046248022466897964,\\n    0.016238540410995483,\\n    -0.005868904292583466,\\n    0.08889073133468628,\\n    0.006721625570207834,\\n    -0.03443409875035286,\\n    0.0010746760526672006,\\n    0.009460551664233208,\\n    -0.02320089191198349,\\n    0.022287946194410324,\\n    -0.012307166121900082,\\n    0.046618979424238205,\\n    -0.007095327600836754,\\n    0.04374462366104126,\\n    -0.03367355465888977,\\n    -0.01719740778207779,\\n    -0.02642054110765457,\\n    -0.01786653883755207,\\n    -0.008955097757279873,\\n    0.008487425744533539,\\n    -0.028401900082826614,\\n    -0.02431010641157627,\\n    0.007617654278874397,\\n    0.027995308861136436,\\n    -0.029383229091763496,\\n    0.03859306126832962,\\n    0.015237865969538689,\\n    -0.04160919785499573,\\n    0.053923215717077255,\\n    0.03657883405685425,\\n    -0.0058037894777953625,\\n    -0.012362365610897541,\\n    0.09030968695878983,\\n    -0.0044023157097399235,\\n    -0.015634972602128983,\\n    -0.03634516894817352,\\n    0.04408255219459534,\\n    -0.027452560141682625,\\n    -0.040538396686315536,\\n    0.005447298288345337,\\n    -0.009160303510725498,\\n    -0.01958056166768074,\\n    -0.03512624651193619,\\n    -0.0045087882317602634,\\n    0.04995451867580414,\\n    -0.019464410841464996,\\n    -0.010661972686648369,\\n    -0.037149570882320404,\\n    0.021744944155216217,\\n    -0.020467083901166916,\\n    0.037855666130781174,\\n    0.06224033981561661,\\n    0.01015221793204546,\\n    0.021227482706308365,\\n    -0.02323673851788044,\\n    0.005240995902568102,\\n    -0.05599822476506233,\\n    0.0107070691883564,\\n    0.035923413932323456,\\n    0.04195265471935272,\\n    -0.000757616653572768,\\n    -0.04316019266843796,\\n    -0.012386453337967396,\\n    -0.022719360888004303,\\n    3.0954541330174834e-07,\\n    -0.04170863330364227,\\n    -0.005444370210170746,\\n    0.060157064348459244,\\n    0.0014096477534621954,\\n    -0.00034851316013373435,\\n    0.00652395561337471,\\n    -0.04744594916701317,\\n    0.06670701503753662,\\n    -0.013656782917678356,\\n    -0.08036239445209503,\\n    0.0054775564931333065,\\n    -0.006003078073263168,\\n    0.07392983138561249,\\n    0.00837341696023941,\\n    -0.0011910010362043977,\\n    -0.039529114961624146,\\n    0.09722302854061127,\\n    -0.0035138637758791447,\\n    -0.00796789675951004,\\n    0.002985938685014844,\\n    0.07572272419929504,\\n    -0.008157709613442421,\\n    0.05063917487859726,\\n    0.02696898952126503,\\n    -0.013463564217090607,\\n    -0.03129386901855469,\\n    -0.014332011342048645,\\n    0.009826648980379105,\\n    -0.01566968858242035,\\n    -0.006194505374878645,\\n    0.008731688372790813,\\n    0.030553443357348442,\\n    -0.020564807578921318,\\n    -0.05243886262178421,\\n    -0.009334541857242584,\\n    -0.05947917699813843,\\n    0.01643078401684761,\\n    0.004542794078588486,\\n    -0.007639060262590647,\\n    0.02434486150741577,\\n    -0.0509818010032177,\\n    0.0014443558175116777,\\n    -0.016359006986021996,\\n    -0.04168160632252693,\\n    0.07633128762245178,\\n    0.010160192847251892,\\n    -0.02037152834236622,\\n    0.0485425740480423,\\n    -0.058993931859731674,\\n    0.05202880874276161,\\n    0.0070481146685779095,\\n    0.0686449259519577,\\n    -0.005109600257128477,\\n    0.007660996168851852,\\n    0.015414988622069359,\\n    0.030449358746409416,\\n    0.005436518229544163,\\n    -0.04171239212155342,\\n    0.04745000973343849,\\n    0.07514990866184235,\\n    0.004984105937182903,\\n    0.011071665212512016,\\n    0.04712620750069618,\\n    0.09067678451538086,\\n    0.002475477522239089,\\n    0.020019371062517166,\\n    -0.034641772508621216,\\n    3.3723488811914344e-34,\\n    -0.0015096972929313779,\\n    -0.026661407202482224,\\n    0.023069005459547043,\\n    -0.0019498432520776987,\\n    -0.004960883874446154,\\n    -0.02734406664967537,\\n    -0.05120456963777542,\\n    -0.03354579210281372,\\n    0.053875815123319626,\\n    -0.040009573101997375,\\n    0.004778997972607613\\n  ]\\n}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Test query to get one document\n",
    "response = es_client.search(\n",
    "    index=\"philosophy\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "        },\n",
    "        \"size\": 1\n",
    "    }\n",
    ")\n",
    "print(\"First document in Elasticsearch:\")\n",
    "json.dumps(response['hits']['hits'][0]['_source'], indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
